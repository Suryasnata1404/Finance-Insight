{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34ebfae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install dependencies (run once if needed)\n",
    "# - Installs pdfplumber, pandas and yfinance for extraction & verification.\n",
    "!pip install pdfplumber pandas yfinance python-dateutil --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b370be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Imports and typing\n",
    "# - Imports required libraries and typing helpers for later cells.\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "import yfinance as yf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d45fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: PDF cleaning helper\n",
    "# - Normalizes whitespace and removes heavily numeric table lines to reduce noise.\n",
    "def pdf_clean(text: str) -> str:\n",
    "    t = re.sub(r'\\u00A0', ' ', text)                      # NBSP\n",
    "    t = re.sub(r'[ \\t]+', ' ', t)                         # collapse spaces/tabs\n",
    "    lines = []\n",
    "    for line in t.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        toks = line.split()\n",
    "        numy = sum(1 for w in toks if re.fullmatch(r'[\\$€£₹]?[-()]?\\d[\\d,\\.]*%?', w))\n",
    "        if numy / max(1, len(toks)) > 0.6:\n",
    "            continue\n",
    "        lines.append(line)\n",
    "    cleaned = \"\\n\".join(lines)\n",
    "    cleaned = re.sub(r'\\n{2,}', '\\n\\n', cleaned)\n",
    "    return cleaned.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e650b6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Extract text and page-level tables using pdfplumber\n",
    "# - Returns full_text string and list of (page_number, pandas.DataFrame) for any tables detected.\n",
    "def extract_text_and_tables_from_pdf(path_or_file) -> Tuple[str, List[Tuple[int, pd.DataFrame]]]:\n",
    "    text_pages = []\n",
    "    tables = []\n",
    "    # path_or_file can be a file path or a file-like object (e.g., uploaded file)\n",
    "    with pdfplumber.open(path_or_file) as pdf:\n",
    "        for i, page in enumerate(pdf.pages, start=1):\n",
    "            txt = page.extract_text() or \"\"\n",
    "            text_pages.append(txt)\n",
    "            try:\n",
    "                for tbl in page.extract_tables():\n",
    "                    if not tbl:\n",
    "                        continue\n",
    "                    header = tbl[0]\n",
    "                    rows = tbl[1:] if len(tbl) > 1 else []\n",
    "                    # ensure columns are unique strings\n",
    "                    cols = [str(h) if h and str(h).strip() else f\"col_{j}\" for j,h in enumerate(header)]\n",
    "                    df = pd.DataFrame(rows, columns=cols)\n",
    "                    tables.append((i, df))\n",
    "            except Exception:\n",
    "                pass\n",
    "    full_text = \"\\n\\n\".join(text_pages)\n",
    "    return full_text, tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb23c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Section segmentation helpers\n",
    "# - Splits cleaned text into paragraphs and identifies sections by keywords.\n",
    "SECTION_KEYWORDS = {\n",
    "    \"Executive Summary\": [\"executive summary\", \"overview\", \"summary of operations\", \"company overview\"],\n",
    "    \"MD&A\": [\"management's discussion\", \"management discussion and analysis\", \"md&a\"],\n",
    "    \"Financial Statements\": [\"financial statements\", \"consolidated statements\", \"consolidated balance sheet\"],\n",
    "    \"Risk Factors\": [\"risk factors\", \"risks related to\"],\n",
    "    \"Notes\": [\"notes to the consolidated\", \"notes to financial statements\"],\n",
    "}\n",
    "\n",
    "def split_paragraphs(text: str) -> List[str]:\n",
    "    return [p.strip() for p in re.split(r'\\n{2,}', text) if p.strip()]\n",
    "\n",
    "def segment_sections(text: str) -> Dict[str, str]:\n",
    "    paragraphs = split_paragraphs(text)\n",
    "     # quick heading detection: build index set of paragraph indices that look like headings\n",
    "    heading_idxs = set()\n",
    "    for i, p in enumerate(paragraphs):\n",
    "        stripped = p.strip()\n",
    "        # uppercase short heading or typical SEC \"Item X.\" markers\n",
    "        if (len(stripped.split()) <= 8 and stripped.isupper()) or re.search(r'^\\s*Item\\s+\\d+[\\.\\:]', stripped, re.I):\n",
    "            heading_idxs.add(i)\n",
    "\n",
    "    sections = {k: \"\" for k in SECTION_KEYWORDS.keys()}\n",
    "    for idx, p in enumerate(paragraphs):\n",
    "        low = p.lower()\n",
    "        for sect, keys in SECTION_KEYWORDS.items():\n",
    "            if any(k in low for k in keys):\n",
    "                buf = [p]\n",
    "                j = idx + 1\n",
    "                while j < len(paragraphs) and j not in heading_idxs and len(paragraphs[j].split()) > 6:\n",
    "                    buf.append(paragraphs[j])\n",
    "                    j += 1\n",
    "                sections[sect] = \"\\n\\n\".join(buf)\n",
    "                break\n",
    "    if not sections[\"Executive Summary\"] and paragraphs:\n",
    "        sections[\"Executive Summary\"] = \"\\n\\n\".join(paragraphs[:2])\n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08300941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 (replacement): Robust table normalization and numeric cleaning\n",
    "# - Uses .iloc to avoid Series key/position ambiguity and DataFrame.apply + Series.map\n",
    "# - Returns numeric DataFrame (same shape) with None where parsing failed.\n",
    "\n",
    "from typing import Any, Optional\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_cell_value(v: Any) -> Optional[float]:\n",
    "    if v is None:\n",
    "        return None\n",
    "    s = str(v).strip()\n",
    "    if s in {\"\", \"-\", \"—\", \"na\", \"n/a\"}:\n",
    "        return None\n",
    "    s = re.sub(r'\\[\\d+\\]','', s)   # remove footnote markers like [1]\n",
    "    if '%' in s:\n",
    "        try:\n",
    "            return float(s.replace('%','').replace(',',''))/100.0\n",
    "        except:\n",
    "            return None\n",
    "    neg = False\n",
    "    if s.startswith('(') and s.endswith(')'):\n",
    "        neg = True\n",
    "        s = s[1:-1]\n",
    "    s = s.replace('$','').replace(',','').replace('—','').strip()\n",
    "    try:\n",
    "        val = float(s)\n",
    "        return -val if neg else val\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def normalize_table_dataframe(df: pd.DataFrame, context_text: str = \"\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a raw table DataFrame to numeric where possible.\n",
    "    Uses context_text to detect scale (in millions/thousands).\n",
    "    \"\"\"\n",
    "    # copy as strings to avoid modifying original\n",
    "    numeric = df.copy(deep=True)\n",
    "\n",
    "    # detect scale from context\n",
    "    ctx = (context_text or \"\").lower()\n",
    "    scale = 1.0\n",
    "    if 'in millions' in ctx or 'amounts in millions' in ctx:\n",
    "        scale = 1e6\n",
    "    elif 'in thousands' in ctx or 'amounts in thousands' in ctx:\n",
    "        scale = 1e3\n",
    "    elif 'in billions' in ctx:\n",
    "        scale = 1e9\n",
    "\n",
    "    # iterate columns by position to avoid integer-label ambiguity\n",
    "    for idx in range(numeric.shape[1]):\n",
    "        # convert column to string first to ensure .map works\n",
    "        col = numeric.iloc[:, idx].astype(str)\n",
    "        # apply parser\n",
    "        parsed = col.map(lambda x: clean_cell_value(x) if x and x != 'nan' else None)\n",
    "        # scale numeric values\n",
    "        parsed = parsed.map(lambda x: None if x is None else x * scale)\n",
    "        # assign back\n",
    "        numeric.iloc[:, idx] = parsed\n",
    "\n",
    "    # coerce dtype: keep as object (mixture of None/float) for display\n",
    "    return numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e264898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Guess table type heuristics\n",
    "# - Looks for key phrases in the table text to classify statement type.\n",
    "def guess_table_type(df: pd.DataFrame) -> str:\n",
    "    text = \" \".join(df.astype(str).fillna('').values.flatten()).lower()\n",
    "    # look at header row too\n",
    "    header_text = \" \".join([str(c).lower() for c in list(df.columns)])\n",
    "    text_all = header_text + \" \" + text\n",
    "    if any(k in text_all for k in [\"total assets\", \"total liabilities\", \"shareholders' equity\", \"total equity\", \"assets\", \"liabilities\"]):\n",
    "        return \"Balance Sheet\"\n",
    "    if any(k in text_all for k in [\"net income\", \"profit\", \"loss\", \"revenue\", \"sales\", \"operating income\", \"cost of goods sold\", \"income before\"]):\n",
    "        return \"Income Statement\"\n",
    "    if any(k in text_all for k in [\"cash flows\", \"net cash\", \"cash and cash equivalents\", \"operating activities\", \"investing activities\", \"financing activities\"]):\n",
    "        return \"Cash Flow\"\n",
    "    # if first column contains \"year\" or \"period\" and other columns are numeric -> likely financial\n",
    "    first_col = \" \".join(df.iloc[:,0].astype(str).fillna('').values).lower()\n",
    "    if \"period\" in first_col or re.search(r'\\b(20\\d{2})\\b', first_col):\n",
    "        return \"Likely Financial Table\"\n",
    "    return \"Unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "807c1a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Ticker extraction & verification\n",
    "# - Finds probable tickers (parentheses / explicit labels) and fetches price + name with yfinance.\n",
    "def extract_probable_tickers(text: str) -> List[str]:\n",
    "    found = []\n",
    "    for m in re.finditer(r'\\((?P<t>[A-Z]{1,5}(?:\\.[A-Z])?)\\)', text):\n",
    "        found.append(m.group(\"t\"))\n",
    "    for m in re.finditer(r'(?:ticker|symbol)\\s*[:\\-]\\s*([A-Z]{1,5}(?:\\.[A-Z])?)', text, re.I):\n",
    "        found.append(m.group(1).upper())\n",
    "    if \"apple\" in text.lower() and \"AAPL\" not in found:\n",
    "        found.append(\"AAPL\")\n",
    "    if \"tesla\" in text.lower() and \"TSLA\" not in found:\n",
    "        found.append(\"TSLA\")\n",
    "    return list(dict.fromkeys(found))\n",
    "\n",
    "def verify_tickers_with_yfinance(tickers: List[str]) -> List[Dict[str, Any]]:\n",
    "    verified = []\n",
    "    for t in tickers:\n",
    "        try:\n",
    "            tk = yf.Ticker(t)\n",
    "            info = tk.info or {}\n",
    "            price = info.get(\"regularMarketPrice\")\n",
    "            name = info.get(\"longName\") or info.get(\"shortName\")\n",
    "            if price is not None:\n",
    "                verified.append({\"ticker\": t, \"price\": price, \"name\": name or \"N/A\"})\n",
    "        except Exception:\n",
    "            pass\n",
    "    return verified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e35bd3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new helper: filter small/garbage tables\n",
    "def filter_tables(raw_tables: List[Tuple[int, pd.DataFrame]],\n",
    "                  min_rows: int = 2,\n",
    "                  min_cols: int = 2,\n",
    "                  min_text_ratio: float = 0.2) -> List[Tuple[int, pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Keep tables that meet simple heuristics:\n",
    "      - at least `min_rows` rows\n",
    "      - at least `min_cols` columns\n",
    "      - at least `min_text_ratio` of cells contain non-numeric text (helpful for header detection)\n",
    "    \"\"\"\n",
    "    kept = []\n",
    "    for page, df in raw_tables:\n",
    "        if df.shape[0] < min_rows or df.shape[1] < min_cols:\n",
    "            continue\n",
    "        # compute fraction of cells that look textual (non purely numeric)\n",
    "        total = df.size\n",
    "        texty = 0\n",
    "        for cell in df.values.flatten():\n",
    "            s = str(cell).strip()\n",
    "            # treat empty / hyphen as non-text\n",
    "            if not s or s in {\"-\", \"—\", \"nan\"}:\n",
    "                continue\n",
    "            # consider as text if contains letters or at least mixed chars\n",
    "            if re.search(r'[A-Za-z]', s) or re.search(r'[,A-Za-z\\$₹£€]', s):\n",
    "                texty += 1\n",
    "        if total == 0:\n",
    "            continue\n",
    "        if (texty / total) < min_text_ratio:\n",
    "            # likely a numeric-only table (which might be okay) — but often it's a fragment; skip for now\n",
    "            continue\n",
    "        kept.append((page, df))\n",
    "    return kept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf5daf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: End-to-end pipeline function\n",
    "# - Given path/file, returns cleaned text, detected sections, parsed tables (raw+numeric+type), and verified tickers.\n",
    "def analyze_pdf_file(path_or_file) -> Dict[str, Any]:\n",
    "    raw_text, tables = extract_text_and_tables_from_pdf(path_or_file)\n",
    "    cleaned = pdf_clean(raw_text)\n",
    "    sections = segment_sections(cleaned)\n",
    "        # inside analyze_pdf_file after obtaining tables:\n",
    "    # filter out tiny/garbage tables first\n",
    "    tables_filtered = filter_tables(tables, min_rows=2, min_cols=2, min_text_ratio=0.15)\n",
    "\n",
    "    parsed_tables = []\n",
    "    for page, df in tables_filtered:\n",
    "        # create small page-context snippet (approx)\n",
    "        ctx_lines = cleaned.splitlines()\n",
    "        start_line = max(0, (page-1)*10)\n",
    "        context = \"\\n\".join(ctx_lines[start_line: start_line + 20])\n",
    "        numeric_df = normalize_table_dataframe(df, context_text=context)\n",
    "        ttype = guess_table_type(df)\n",
    "        parsed_tables.append({\"page\": page, \"type\": ttype, \"raw\": df, \"numeric\": numeric_df})\n",
    "\n",
    "    tickers = extract_probable_tickers(cleaned)\n",
    "    verified = verify_tickers_with_yfinance(tickers)\n",
    "    return {\"text\": cleaned, \"sections\": sections, \"tables\": parsed_tables, \"verified\": verified}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e046318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sections detected ===\n",
      "- Executive Summary: FOUND\n",
      "- MD&A: not found\n",
      "- Financial Statements: not found\n",
      "- Risk Factors: not found\n",
      "- Notes: not found\n",
      "\n",
      "=== Tables found by pdfplumber (raw count) === 35\n",
      "=== Parsed / kept tables (after filtering) === 35\n",
      "Pages with kept tables: [4, 5, 6, 7, 7, 8, 8, 9, 10, 11, 12, 13, 13, 14, 15, 15, 15, 16, 16, 17, 17, 18, 18, 19, 19, 19, 20, 24, 25, 25, 25, 25, 29, 30, 34]\n",
      "\n",
      "--- First kept table: Page 4 — Type: Balance Sheet ---\n",
      "\n",
      "Raw (head):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assets</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Current assets</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cash and cash equivalents</td>\n",
       "      <td>$</td>\n",
       "      <td>15,587</td>\n",
       "      <td></td>\n",
       "      <td>$</td>\n",
       "      <td>16,139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Short-term investments</td>\n",
       "      <td>21,195</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>20,424</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accounts receivable, net</td>\n",
       "      <td>3,838</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>4,418</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inventory</td>\n",
       "      <td>14,570</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>12,017</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Prepaid expenses and other current assets</td>\n",
       "      <td>5,943</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>5,362</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Total current assets</td>\n",
       "      <td>61,133</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>58,360</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Operating lease vehicles, net</td>\n",
       "      <td>5,230</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>5,581</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Solar energy systems, net</td>\n",
       "      <td>4,788</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>4,924</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Property, plant and equipment, net</td>\n",
       "      <td>38,574</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>35,836</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Assets   col_1   col_2 col_3   col_4  \\\n",
       "0                             Current assets            None                 \n",
       "1                  Cash and cash equivalents       $  15,587             $   \n",
       "2                     Short-term investments  21,195    None        20,424   \n",
       "3                   Accounts receivable, net   3,838    None         4,418   \n",
       "4                                  Inventory  14,570    None        12,017   \n",
       "5  Prepaid expenses and other current assets   5,943    None         5,362   \n",
       "6                       Total current assets  61,133    None        58,360   \n",
       "7              Operating lease vehicles, net   5,230    None         5,581   \n",
       "8                  Solar energy systems, net   4,788    None         4,924   \n",
       "9         Property, plant and equipment, net  38,574    None        35,836   \n",
       "\n",
       "    col_5  \n",
       "0    None  \n",
       "1  16,139  \n",
       "2    None  \n",
       "3    None  \n",
       "4    None  \n",
       "5    None  \n",
       "6    None  \n",
       "7    None  \n",
       "8    None  \n",
       "9    None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric (normalized) preview (head):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assets</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15587.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>21195.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>20424.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>3838.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>4418.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>14570.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>12017.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>5943.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>5362.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>61133.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>58360.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>5230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>5581.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>4788.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>4924.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>38574.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>35836.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Assets    col_1    col_2 col_3    col_4    col_5\n",
       "0   None      NaN      NaN  None      NaN      NaN\n",
       "1   None      NaN  15587.0  None      NaN  16139.0\n",
       "2   None  21195.0      NaN  None  20424.0      NaN\n",
       "3   None   3838.0      NaN  None   4418.0      NaN\n",
       "4   None  14570.0      NaN  None  12017.0      NaN\n",
       "5   None   5943.0      NaN  None   5362.0      NaN\n",
       "6   None  61133.0      NaN  None  58360.0      NaN\n",
       "7   None   5230.0      NaN  None   5581.0      NaN\n",
       "8   None   4788.0      NaN  None   4924.0      NaN\n",
       "9   None  38574.0      NaN  None  35836.0      NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw table shape: (40, 6); Numeric table shape: (40, 6)\n",
      "\n",
      "Sample unparsed cells (row, col, raw):\n",
      "  - (0,0) -> Current assets\n",
      "  - (0,3) -> \n",
      "  - (1,0) -> Cash and cash equivalents\n",
      "  - (1,3) -> \n",
      "  - (2,0) -> Short-term investments\n",
      "  - (2,3) -> \n",
      "  - (3,0) -> Accounts receivable, net\n",
      "  - (3,3) -> \n",
      "  - (4,0) -> Inventory\n",
      "  - (4,3) -> \n",
      "\n",
      "=== Verified tickers (yfinance) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>price</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>401.25</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker   price         name\n",
       "0   TSLA  401.25  Tesla, Inc."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 10 (replacement): Demo run — print filtered table counts and display first kept table\n",
    "# - Run analyze_pdf_file on a PDF, show how many tables remained after filtering and display the first one.\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "# <-- update this to your PDF file path (use raw string r\"...\" or forward slashes)\n",
    "pdf_path = r\"D:/Finance-Insight/data/raw/filings/Tesla_10-Q.pdf\"\n",
    "\n",
    "# run pipeline\n",
    "res = analyze_pdf_file(pdf_path)\n",
    "\n",
    "# basic summary\n",
    "print(\"=== Sections detected ===\")\n",
    "for name, body in res[\"sections\"].items():\n",
    "    print(f\"- {name}: {'FOUND' if body else 'not found'}\")\n",
    "\n",
    "tables = res.get(\"tables\", [])\n",
    "print(f\"\\n=== Tables found by pdfplumber (raw count) === {len(tables)}\")\n",
    "\n",
    "# If you used filter_tables inside analyze_pdf_file, parsed_tables is the filtered list.\n",
    "parsed_tables = res.get(\"tables\", [])  # analyze_pdf_file returns parsed tables (filtered + numeric)\n",
    "print(f\"=== Parsed / kept tables (after filtering) === {len(parsed_tables)}\")\n",
    "\n",
    "if not parsed_tables:\n",
    "    print(\"No parsed tables kept. Try lowering filter thresholds (min_rows/min_cols/min_text_ratio) or inspect raw extraction.\")\n",
    "else:\n",
    "    # show pages kept\n",
    "    pages = [t[\"page\"] for t in parsed_tables]\n",
    "    print(\"Pages with kept tables:\", pages)\n",
    "\n",
    "    # display first kept table (raw + numeric)\n",
    "    first = parsed_tables[0]\n",
    "    print(f\"\\n--- First kept table: Page {first['page']} — Type: {first.get('type','Unknown')} ---\\n\")\n",
    "    print(\"Raw (head):\")\n",
    "    display(first[\"raw\"].head(10))\n",
    "    print(\"Numeric (normalized) preview (head):\")\n",
    "    display(first[\"numeric\"].head(10))\n",
    "\n",
    "    # show small diagnostics for the first table\n",
    "    raw_shape = first[\"raw\"].shape\n",
    "    num_shape = first[\"numeric\"].shape\n",
    "    print(f\"\\nRaw table shape: {raw_shape}; Numeric table shape: {num_shape}\")\n",
    "    # show few sample cells that didn't parse (to help tune clean_cell_value)\n",
    "    sample_bad = []\n",
    "    for r in range(min(5, num_shape[0])):\n",
    "        for c in range(min(5, num_shape[1])):\n",
    "            val = first[\"numeric\"].iloc[r, c]\n",
    "            if val is None:\n",
    "                sample_bad.append((r, c, str(first[\"raw\"].iloc[r, c])))\n",
    "    if sample_bad:\n",
    "        print(\"\\nSample unparsed cells (row, col, raw):\")\n",
    "        for r,c,raw in sample_bad[:10]:\n",
    "            print(f\"  - ({r},{c}) -> {raw}\")\n",
    "\n",
    "# show verified tickers\n",
    "print(\"\\n=== Verified tickers (yfinance) ===\")\n",
    "verified = res.get(\"verified\", [])\n",
    "if verified:\n",
    "    display(pd.DataFrame(verified))\n",
    "else:\n",
    "    print(\"No tickers verified automatically. Try adding company name or 'ticker: AAPL' in the text.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33881449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ../segmentation_and_tables.py (edit it to paste functions for production).\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: (Optional) Write a reusable module file segmentation_and_tables.py\n",
    "# - This exports analyze_pdf_file and helpers so app.py can import them.\n",
    "module_code = \"\"\"\n",
    "# segmentation_and_tables.py\n",
    "# Generated from milestone4 notebook - contains helpers for segmentation & table parsing.\n",
    "# (Only a wrapper that imports functions from the notebook environment if needed.)\n",
    "# Note: If running as a module, ensure dependencies (pdfplumber, pandas, yfinance) are installed.\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "import re, pdfplumber, pandas as pd\n",
    "from datetime import datetime\n",
    "# (Paste the function definitions from notebook here when moving to a file.)\n",
    "# For brevity, create this module manually by copying functions: pdf_clean, extract_text_and_tables_from_pdf, segment_sections, normalize_table_dataframe, guess_table_type, extract_probable_tickers, verify_tickers_with_yfinance, analyze_pdf_file\n",
    "\"\"\"\n",
    "with open(\"../segmentation_and_tables.py\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(module_code)\n",
    "print(\"Wrote ../segmentation_and_tables.py (edit it to paste functions for production).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d19b2a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Integration steps:\n",
      "1) Copy stable functions (pdf_clean, extract_text_and_tables_from_pdf, segment_sections,\n",
      "   normalize_table_dataframe, guess_table_type, extract_probable_tickers, verify_tickers_with_yfinance, analyze_pdf_file)\n",
      "   into a new file at project root named `segmentation_and_tables.py`.\n",
      "\n",
      "2) In app.py (Streamlit), import:\n",
      "   from segmentation_and_tables import analyze_pdf_file\n",
      "\n",
      "3) When user uploads a PDF in Streamlit, pass the uploaded file object to analyze_pdf_file(uploaded_file)\n",
      "   and display sections and tables: st.expander for sections, st.dataframe for tables.\n",
      "\n",
      "4) Add a 'Download JSON' button:\n",
      "   st.download_button(..., json.dumps(result, default=str), file_name=\"milestone4_results.json\")\n",
      "\n",
      "If you want, I can now produce the actual `segmentation_and_tables.py` file content ready to paste.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Integration instructions (copy-paste)\n",
    "# - To integrate with your app.py:\n",
    "print(\"\"\"\n",
    "Integration steps:\n",
    "1) Copy stable functions (pdf_clean, extract_text_and_tables_from_pdf, segment_sections,\n",
    "   normalize_table_dataframe, guess_table_type, extract_probable_tickers, verify_tickers_with_yfinance, analyze_pdf_file)\n",
    "   into a new file at project root named `segmentation_and_tables.py`.\n",
    "\n",
    "2) In app.py (Streamlit), import:\n",
    "   from segmentation_and_tables import analyze_pdf_file\n",
    "\n",
    "3) When user uploads a PDF in Streamlit, pass the uploaded file object to analyze_pdf_file(uploaded_file)\n",
    "   and display sections and tables: st.expander for sections, st.dataframe for tables.\n",
    "\n",
    "4) Add a 'Download JSON' button:\n",
    "   st.download_button(..., json.dumps(result, default=str), file_name=\"milestone4_results.json\")\n",
    "\n",
    "If you want, I can now produce the actual `segmentation_and_tables.py` file content ready to paste.\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
