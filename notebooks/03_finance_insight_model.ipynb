{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce1H0n7Nz81S",
        "outputId": "e3887a00-24f1-484d-96ea-4f13fe269e40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##Run this in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHumLuBVTp4V",
        "outputId": "db37fab7-182c-46de-e134-6177d7a74211"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo: Suryasnata1404/Finance-Insight\n",
            "Paste your GitHub PAT (input hidden): Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Cloning into '/content/repo'...\n",
            "remote: Enumerating objects: 186, done.\u001b[K\n",
            "remote: Counting objects: 100% (186/186), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 186 (delta 88), reused 159 (delta 61), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (186/186), 1.60 MiB | 7.36 MiB/s, done.\n",
            "Resolving deltas: 100% (88/88), done.\n",
            "Repo files: ['scripts', '01_test_ner.ipynb', '.gitignore', 'requirements.txt', 'README.md', '.git', 'notebooks', 'data']\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "GITHUB_REPO = \"Suryasnata1404/Finance-Insight\"\n",
        "print(\"Repo:\", GITHUB_REPO)\n",
        "\n",
        "token = getpass(\"Paste your GitHub PAT (input hidden): \")\n",
        "clone_url = f\"https://{token}@github.com/{GITHUB_REPO}.git\"\n",
        "\n",
        "# clone into /content/repo\n",
        "!rm -rf /content/repo\n",
        "!git clone {clone_url} /content/repo\n",
        "\n",
        "# show files\n",
        "import os\n",
        "print(\"Repo files:\", os.listdir(\"/content/repo\")[:40])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpPEHDzbT0TL",
        "outputId": "7ad76674-9955-48d1-d101-4b15e892ce29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open /content/drive/MyDrive/Finance-Insight/data/processed/ner_auto_splits.zip, /content/drive/MyDrive/Finance-Insight/data/processed/ner_auto_splits.zip.zip or /content/drive/MyDrive/Finance-Insight/data/processed/ner_auto_splits.zip.ZIP.\n",
            "total 6332\n",
            "drwxr-xr-x 2 root root    4096 Nov  6 08:35 .\n",
            "drwxr-xr-x 3 root root    4096 Nov  6 08:35 ..\n",
            "-rw-r--r-- 1 root root     388 Nov  6 08:35 label_map.json\n",
            "-rw-r--r-- 1 root root  442844 Nov  6 08:35 test.jsonl\n",
            "-rw-r--r-- 1 root root 5504055 Nov  6 08:35 train.jsonl\n",
            "-rw-r--r-- 1 root root  519794 Nov  6 08:35 validation.jsonl\n"
          ]
        }
      ],
      "source": [
        "# unzip dataset into repo data/processed/\n",
        "!unzip -q /content/drive/MyDrive/Finance-Insight/data/processed/ner_auto_splits.zip -d /content/repo/data/processed/\n",
        "!ls -la /content/repo/data/processed/ner_auto_splits | sed -n '1,200p'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN2I4qKNu3wZ",
        "outputId": "c43a6abf-4572-4310-9691-04f432879e8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 6.2M\n",
            "-rw------- 1 root root  411 Oct 31 11:41 label_map.json\n",
            "-rw------- 1 root root 434K Oct 31 11:41 test.jsonl\n",
            "-rw------- 1 root root 5.3M Oct 31 11:41 train.jsonl\n",
            "-rw------- 1 root root 509K Oct 31 11:41 validation.jsonl\n"
          ]
        }
      ],
      "source": [
        "!ls -lh /content/drive/MyDrive/Finance-Insight/data/processed/ner_auto_splits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGRNGoeDqPp7",
        "outputId": "014f67df-9f28-4288-91ac-d3212c9d3b34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "transformers: 4.57.1\n",
            "datasets: 4.0.0\n",
            "torch: 2.8.0+cu126 | CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install required libraries\n",
        "!pip install -q transformers datasets evaluate seqeval accelerate huggingface_hub\n",
        "\n",
        "# Step 2: Check versions and GPU availability\n",
        "import transformers, datasets, torch\n",
        "\n",
        "print(\"transformers:\", transformers.__version__)\n",
        "print(\"datasets:\", datasets.__version__)\n",
        "print(\"torch:\", torch.__version__, \"| CUDA available:\", torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkzeT2khvteH",
        "outputId": "130e979f-d2c7-44ca-ca50-84412e815e42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“ Repo files:\n",
            " - README.md\n",
            " - .git\n",
            " - data\n",
            " - notebooks\n",
            " - scripts\n",
            " - .gitignore\n",
            " - 01_test_ner.ipynb\n",
            " - requirements.txt\n",
            "âœ… Found training file: /content/repo/scripts/7_train_quick_ner.py\n",
            "ðŸ”§ Patched output_dir â†’ /content/drive/MyDrive/Finance-Insight/ner_results\n",
            "import os\n",
            "import json\n",
            "import torch\n",
            "from datasets import load_dataset\n",
            "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification\n",
            "import evaluate\n",
            "\n",
            "# --- Config ---\n",
            "DATA_DIR = \"data/processed/ner_auto_splits\"\n",
            "MODEL_NAME = \"ProsusAI/finbert\"\n",
            "BATCH_SIZE = 2  \n",
            "EPOCHS = 3\n",
            "OUTPUT_DIR = \"data/finbert_ner_results\" \n",
            "\n",
            "# --- Device Check ---\n",
            "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
            "print(f\"Using device: {device}\")\n",
            "\n",
            "# --- Load dataset ---\n",
            "dataset = load_dataset(\"json\", data_files={\n",
            "    \"train\": f\"{DATA_DIR}/train.jsonl\",\n",
            "    \"validation\": f\"{DATA_DIR}/validation.jsonl\",\n",
            "    \"test\": f\"{DATA_DIR}/test.jsonl\"\n",
            "})\n",
            "\n",
            "# --- Print dataset sizes ---\n",
            "print(\"ðŸ“Š Dataset sizes:\", {k: len(v) for k, v in dataset.items()})\n",
            "\n",
            "# --- Load label map ---\n",
            "with open(f\"{DATA_DIR}/label_map.json\") as f:\n",
            "    label_info = json.load(f)\n",
            "label2id = label_info[\"label2id\"]\n",
            "id2label = {int(k): v for k, v in label_info[\"id2label\"].items()}\n",
            "\n",
            "# --- Load tokenizer and model ---\n",
            "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
            "model = AutoModelForTokenClassification.from_pretrained(\n",
            "    MODEL_NAME,\n",
            "    num_labels=len(label2id),\n",
            "    id2label=id2label,\n"
          ]
        }
      ],
      "source": [
        "# âœ… Step 1: Set paths\n",
        "REPO_DIR = \"/content/repo\"   # where your GitHub repo was cloned\n",
        "TRAIN_FILE = f\"{REPO_DIR}/scripts/7_train_quick_ner.py\"   # ðŸ‘ˆ change if your filename differs\n",
        "DRIVE_OUT = \"/content/drive/MyDrive/Finance-Insight/ner_results\"\n",
        "\n",
        "import os, sys\n",
        "\n",
        "# âœ… Step 2: Verify the repo contents\n",
        "print(\"ðŸ“ Repo files:\")\n",
        "for f in os.listdir(REPO_DIR):\n",
        "    print(\" -\", f)\n",
        "\n",
        "# âœ… Step 3: Check training file\n",
        "if not os.path.exists(TRAIN_FILE):\n",
        "    sys.exit(f\"âŒ Train file not found at {TRAIN_FILE}\\nCheck the exact file name above and update TRAIN_FILE.\")\n",
        "else:\n",
        "    print(f\"âœ… Found training file: {TRAIN_FILE}\")\n",
        "\n",
        "# âœ… Step 4: Patch output directory inside your Python script\n",
        "with open(TRAIN_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "    code = f.read()\n",
        "\n",
        "new_code = code.replace('output_dir=\"./ner_results\"', f'output_dir=\"{DRIVE_OUT}\"')\n",
        "\n",
        "with open(TRAIN_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(new_code)\n",
        "\n",
        "print(\"ðŸ”§ Patched output_dir â†’\", DRIVE_OUT)\n",
        "\n",
        "# âœ… Step 5: Confirm first 40 lines\n",
        "!head -n 40 \"$TRAIN_FILE\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNbJKuorzfdM",
        "outputId": "055139c7-98ea-4b15-9117-a2f9dee66d14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train.jsonl exists: True  size: 5513339\n",
            "validation.jsonl exists: True  size: 520955\n",
            "test.jsonl exists: True  size: 444005\n",
            "label_map.json exists: True  size: 411\n",
            "sample tokens: ['2011', '-', '09', '-', '15']\n",
            "sample ner_tags: [0, 4, 4, 4, 4]\n",
            "sample tokens: ['693']\n",
            "sample ner_tags: [8]\n"
          ]
        }
      ],
      "source": [
        "import os, json\n",
        "DATA_DIR = \"/content/drive/MyDrive/Finance-Insight/data/processed/ner_auto_splits\"\n",
        "\n",
        "\n",
        "for fname in (\"train.jsonl\",\"validation.jsonl\",\"test.jsonl\",\"label_map.json\"):\n",
        "    path = os.path.join(DATA_DIR, fname)\n",
        "    print(fname, \"exists:\", os.path.exists(path), \" size:\", os.path.getsize(path) if os.path.exists(path) else \"NA\")\n",
        "\n",
        "# print small sample\n",
        "with open(os.path.join(DATA_DIR, \"train.jsonl\"), encoding='utf-8') as f:\n",
        "    for i,line in enumerate(f):\n",
        "        if i>=2: break\n",
        "        r=json.loads(line)\n",
        "        print(\"sample tokens:\", r.get(\"tokens\")[:10])\n",
        "        print(\"sample ner_tags:\", r.get(\"ner_tags\")[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eOsNQhm-jlH",
        "outputId": "0a40d5f5-a9cf-4646-8972-3d4e74560ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Finance-Insight\n",
            "mv: cannot stat '7_train_quick_ner.py': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Finance-Insight\n",
        "!mkdir -p scripts\n",
        "!mv 7_train_quick_ner.py scripts/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQHiyAY4_tUl"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/drive/MyDrive/Finance-Insight/data/processed\n",
        "!mv /content/drive/MyDrive/Finance-Insight/ner_auto_splits.zip /content/drive/MyDrive/Finance-Insight/data/processed/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4tbFuAqEceF",
        "outputId": "b0d867fa-790a-41ec-9e14-4702d0f79b5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 6328\n",
            "-rw------- 1 root root     411 Oct 31 11:41 label_map.json\n",
            "-rw------- 1 root root  444005 Oct 31 11:41 test.jsonl\n",
            "-rw------- 1 root root 5513339 Oct 31 11:41 train.jsonl\n",
            "-rw------- 1 root root  520955 Oct 31 11:41 validation.jsonl\n"
          ]
        }
      ],
      "source": [
        "# create expected dir in Google Drive\n",
        "!mkdir -p /content/drive/MyDrive/Finance-Insight/data/processed\n",
        "\n",
        "# copy your working dataset from /content/repo â†’ Drive\n",
        "!cp -r /content/repo/data/processed/ner_auto_splits /content/drive/MyDrive/Finance-Insight/data/processed/\n",
        "\n",
        "# verify copy worked\n",
        "!ls -la /content/drive/MyDrive/Finance-Insight/data/processed/ner_auto_splits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-2zc6ANCZC3",
        "outputId": "139bd15a-f4a3-4a8b-a787-474201bf2c45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Finance-Insight/data/processed/ner_auto_splits/train.jsonl\n"
          ]
        }
      ],
      "source": [
        "# Search for train.jsonl in your Drive\n",
        "!find /content/drive/MyDrive/Finance-Insight -type f -name \"train.jsonl\" -print || true\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e548fviOChlN"
      },
      "outputs": [],
      "source": [
        "# create expected dirs and move dataset into place\n",
        "mkdir -p /content/drive/MyDrive/Finance-Insight/data/processed\n",
        "mv -v /content/drive/MyDrive/Finance-Insight/ner_auto_splits /content/drive/MyDrive/Finance-Insight/data/processed/ 2>/dev/null || true\n",
        "\n",
        "# show destination\n",
        "ls -la /content/drive/MyDrive/Finance-Insight/data/processed/ner_auto_splits | sed -n '1,200p'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIklALXcmtef",
        "outputId": "c8b82fc9-7910-404a-fcf4-a68733df6491"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training will run on: CUDA\n",
            "/content/drive/MyDrive/Finance-Insight\n",
            "âœ… Found training script: scripts/7_train_quick_ner.py\n",
            "ðŸ“‚ Output dir ready: data/finbert_ner_results\n",
            "\n",
            "ðŸ§© Starting FinBERT NER fine-tuning...\n",
            "\n",
            "2025-11-01 09:59:09.240552: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761991149.259962   11447 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761991149.265900   11447 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761991149.281329   11447 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761991149.281353   11447 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761991149.281356   11447 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761991149.281362   11447 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-01 09:59:09.285925: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Using device: cuda\n",
            "ðŸ“Š Dataset sizes: {'train': 9284, 'validation': 1161, 'test': 1161}\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
            "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([9, 768]) in the model instantiated\n",
            "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([9]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Map: 100% 1161/1161 [00:00<00:00, 3173.91 examples/s]\n",
            "/content/drive/MyDrive/Finance-Insight/scripts/7_train_quick_ner.py:94: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "{'loss': 0.4173, 'grad_norm': 3.0581586360931396, 'learning_rate': 2.8925032313657906e-05, 'epoch': 0.11}\n",
            "{'loss': 0.2964, 'grad_norm': 4.494197845458984, 'learning_rate': 2.784791038345541e-05, 'epoch': 0.22}\n",
            "{'loss': 0.2823, 'grad_norm': 2.263059139251709, 'learning_rate': 2.677078845325291e-05, 'epoch': 0.32}\n",
            "{'loss': 0.2766, 'grad_norm': 0.37443527579307556, 'learning_rate': 2.5693666523050412e-05, 'epoch': 0.43}\n",
            "{'loss': 0.2597, 'grad_norm': 4.7031402587890625, 'learning_rate': 2.4616544592847912e-05, 'epoch': 0.54}\n",
            "{'loss': 0.2337, 'grad_norm': 6.580427169799805, 'learning_rate': 2.3539422662645412e-05, 'epoch': 0.65}\n",
            "{'loss': 0.2431, 'grad_norm': 2.021798610687256, 'learning_rate': 2.246230073244291e-05, 'epoch': 0.75}\n",
            "{'loss': 0.2437, 'grad_norm': 0.03629547357559204, 'learning_rate': 2.1385178802240415e-05, 'epoch': 0.86}\n",
            "{'loss': 0.2404, 'grad_norm': 2.4925308227539062, 'learning_rate': 2.0308056872037915e-05, 'epoch': 0.97}\n",
            " 33% 4642/13926 [04:49<08:38, 17.90it/s]\n",
            "  0% 0/581 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 12/581 [00:00<00:05, 112.77it/s]\u001b[A\n",
            "  4% 24/581 [00:00<00:05, 108.69it/s]\u001b[A\n",
            "  6% 35/581 [00:00<00:05, 104.92it/s]\u001b[A\n",
            "  8% 46/581 [00:00<00:05, 96.16it/s] \u001b[A\n",
            " 10% 56/581 [00:00<00:05, 97.37it/s]\u001b[A\n",
            " 11% 66/581 [00:00<00:05, 93.04it/s]\u001b[A\n",
            " 13% 76/581 [00:00<00:05, 85.11it/s]\u001b[A\n",
            " 15% 85/581 [00:00<00:05, 86.07it/s]\u001b[A\n",
            " 17% 96/581 [00:01<00:05, 91.57it/s]\u001b[A\n",
            " 18% 106/581 [00:01<00:05, 84.89it/s]\u001b[A\n",
            " 20% 116/581 [00:01<00:05, 88.14it/s]\u001b[A\n",
            " 22% 127/581 [00:01<00:04, 93.10it/s]\u001b[A\n",
            " 24% 138/581 [00:01<00:04, 97.70it/s]\u001b[A\n",
            " 25% 148/581 [00:01<00:04, 98.32it/s]\u001b[A\n",
            " 27% 159/581 [00:01<00:04, 100.74it/s]\u001b[A\n",
            " 29% 170/581 [00:01<00:04, 91.45it/s] \u001b[A\n",
            " 31% 181/581 [00:01<00:04, 95.08it/s]\u001b[A\n",
            " 33% 192/581 [00:02<00:03, 97.75it/s]\u001b[A\n",
            " 35% 203/581 [00:02<00:03, 98.73it/s]\u001b[A\n",
            " 37% 214/581 [00:02<00:03, 101.36it/s]\u001b[A\n",
            " 39% 225/581 [00:02<00:03, 94.91it/s] \u001b[A\n",
            " 41% 236/581 [00:02<00:03, 98.18it/s]\u001b[A\n",
            " 43% 247/581 [00:02<00:03, 89.82it/s]\u001b[A\n",
            " 44% 258/581 [00:02<00:03, 92.85it/s]\u001b[A\n",
            " 46% 268/581 [00:02<00:03, 92.59it/s]\u001b[A\n",
            " 48% 279/581 [00:02<00:03, 96.47it/s]\u001b[A\n",
            " 50% 290/581 [00:03<00:02, 98.80it/s]\u001b[A\n",
            " 52% 300/581 [00:03<00:02, 95.41it/s]\u001b[A\n",
            " 53% 310/581 [00:03<00:03, 87.60it/s]\u001b[A\n",
            " 55% 319/581 [00:03<00:03, 82.18it/s]\u001b[A\n",
            " 57% 330/581 [00:03<00:02, 88.28it/s]\u001b[A\n",
            " 59% 341/581 [00:03<00:02, 93.92it/s]\u001b[A\n",
            " 61% 352/581 [00:03<00:02, 97.09it/s]\u001b[A\n",
            " 62% 362/581 [00:03<00:02, 86.04it/s]\u001b[A\n",
            " 64% 371/581 [00:04<00:02, 71.47it/s]\u001b[A\n",
            " 66% 382/581 [00:04<00:02, 79.55it/s]\u001b[A\n",
            " 68% 393/581 [00:04<00:02, 86.07it/s]\u001b[A\n",
            " 69% 403/581 [00:04<00:02, 80.84it/s]\u001b[A\n",
            " 71% 413/581 [00:04<00:01, 84.49it/s]\u001b[A\n",
            " 73% 424/581 [00:04<00:01, 89.98it/s]\u001b[A\n",
            " 75% 435/581 [00:04<00:01, 94.35it/s]\u001b[A\n",
            " 77% 445/581 [00:04<00:01, 91.61it/s]\u001b[A\n",
            " 78% 455/581 [00:05<00:01, 75.51it/s]\u001b[A\n",
            " 80% 466/581 [00:05<00:01, 82.29it/s]\u001b[A\n",
            " 82% 477/581 [00:05<00:01, 80.52it/s]\u001b[A\n",
            " 84% 487/581 [00:05<00:01, 84.66it/s]\u001b[A\n",
            " 85% 496/581 [00:05<00:01, 78.85it/s]\u001b[A\n",
            " 87% 505/581 [00:05<00:00, 77.18it/s]\u001b[A\n",
            " 89% 516/581 [00:05<00:00, 83.56it/s]\u001b[A\n",
            " 90% 525/581 [00:05<00:00, 85.02it/s]\u001b[A\n",
            " 92% 534/581 [00:05<00:00, 81.91it/s]\u001b[A\n",
            " 93% 543/581 [00:06<00:00, 68.85it/s]\u001b[A\n",
            " 95% 554/581 [00:06<00:00, 77.60it/s]\u001b[A\n",
            " 97% 564/581 [00:06<00:00, 76.18it/s]\u001b[A\n",
            " 99% 575/581 [00:06<00:00, 82.63it/s]\u001b[A/usr/local/lib/python3.12/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                        \n",
            "\u001b[A{'eval_loss': 0.2636879086494446, 'eval_precision': 0.6795507965526247, 'eval_recall': 0.784207353827607, 'eval_f1': 0.7281376801455156, 'eval_accuracy': 0.9155279068954671, 'eval_runtime': 7.1626, 'eval_samples_per_second': 162.093, 'eval_steps_per_second': 81.116, 'epoch': 1.0}\n",
            " 33% 4642/13926 [04:56<08:38, 17.90it/s]\n",
            "100% 581/581 [00:07<00:00, 82.63it/s]\u001b[A\n",
            "{'loss': 0.1701, 'grad_norm': 32.517032623291016, 'learning_rate': 1.9230934941835415e-05, 'epoch': 1.08}\n",
            "{'loss': 0.1855, 'grad_norm': 0.04086313024163246, 'learning_rate': 1.8153813011632914e-05, 'epoch': 1.18}\n",
            "{'loss': 0.1735, 'grad_norm': 1.0145783424377441, 'learning_rate': 1.707669108143042e-05, 'epoch': 1.29}\n",
            "{'loss': 0.1521, 'grad_norm': 2.830015182495117, 'learning_rate': 1.599956915122792e-05, 'epoch': 1.4}\n",
            "{'loss': 0.2125, 'grad_norm': 0.06889401376247406, 'learning_rate': 1.492244722102542e-05, 'epoch': 1.51}\n",
            "{'loss': 0.197, 'grad_norm': 3.8474981784820557, 'learning_rate': 1.3845325290822922e-05, 'epoch': 1.62}\n",
            "{'loss': 0.1621, 'grad_norm': 2.891709089279175, 'learning_rate': 1.2768203360620422e-05, 'epoch': 1.72}\n",
            "{'loss': 0.1739, 'grad_norm': 0.009431217797100544, 'learning_rate': 1.1691081430417924e-05, 'epoch': 1.83}\n",
            "{'loss': 0.1681, 'grad_norm': 0.027081109583377838, 'learning_rate': 1.0613959500215424e-05, 'epoch': 1.94}\n",
            " 67% 9284/13926 [09:53<04:29, 17.20it/s]\n",
            "  0% 0/581 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 12/581 [00:00<00:05, 112.57it/s]\u001b[A\n",
            "  4% 24/581 [00:00<00:05, 104.62it/s]\u001b[A\n",
            "  6% 35/581 [00:00<00:05, 103.27it/s]\u001b[A\n",
            "  8% 46/581 [00:00<00:05, 104.53it/s]\u001b[A\n",
            " 10% 57/581 [00:00<00:05, 99.98it/s] \u001b[A\n",
            " 12% 68/581 [00:00<00:05, 101.13it/s]\u001b[A\n",
            " 14% 79/581 [00:00<00:05, 90.16it/s] \u001b[A\n",
            " 15% 90/581 [00:00<00:05, 94.97it/s]\u001b[A\n",
            " 17% 100/581 [00:01<00:05, 94.13it/s]\u001b[A\n",
            " 19% 110/581 [00:01<00:05, 86.24it/s]\u001b[A\n",
            " 21% 121/581 [00:01<00:05, 91.53it/s]\u001b[A\n",
            " 23% 132/581 [00:01<00:04, 94.53it/s]\u001b[A\n",
            " 24% 142/581 [00:01<00:04, 94.46it/s]\u001b[A\n",
            " 26% 152/581 [00:01<00:04, 95.43it/s]\u001b[A\n",
            " 28% 162/581 [00:01<00:04, 87.15it/s]\u001b[A\n",
            " 30% 173/581 [00:01<00:04, 92.01it/s]\u001b[A\n",
            " 32% 184/581 [00:01<00:04, 96.40it/s]\u001b[A\n",
            " 33% 194/581 [00:02<00:04, 94.80it/s]\u001b[A\n",
            " 35% 205/581 [00:02<00:03, 98.08it/s]\u001b[A\n",
            " 37% 216/581 [00:02<00:03, 101.41it/s]\u001b[A\n",
            " 39% 227/581 [00:02<00:03, 94.60it/s] \u001b[A\n",
            " 41% 238/581 [00:02<00:03, 97.64it/s]\u001b[A\n",
            " 43% 248/581 [00:02<00:03, 85.52it/s]\u001b[A\n",
            " 45% 259/581 [00:02<00:03, 89.74it/s]\u001b[A\n",
            " 46% 270/581 [00:02<00:03, 94.17it/s]\u001b[A\n",
            " 48% 281/581 [00:02<00:03, 96.65it/s]\u001b[A\n",
            " 50% 291/581 [00:03<00:03, 95.13it/s]\u001b[A\n",
            " 52% 301/581 [00:03<00:03, 93.05it/s]\u001b[A\n",
            " 54% 311/581 [00:03<00:03, 85.61it/s]\u001b[A\n",
            " 55% 320/581 [00:03<00:03, 81.14it/s]\u001b[A\n",
            " 57% 331/581 [00:03<00:02, 87.90it/s]\u001b[A\n",
            " 59% 342/581 [00:03<00:02, 92.65it/s]\u001b[A\n",
            " 61% 353/581 [00:03<00:02, 95.06it/s]\u001b[A\n",
            " 62% 363/581 [00:03<00:02, 87.67it/s]\u001b[A\n",
            " 64% 372/581 [00:04<00:02, 71.71it/s]\u001b[A\n",
            " 66% 382/581 [00:04<00:02, 76.95it/s]\u001b[A\n",
            " 67% 391/581 [00:04<00:02, 79.04it/s]\u001b[A\n",
            " 69% 400/581 [00:04<00:02, 74.72it/s]\u001b[A\n",
            " 70% 408/581 [00:04<00:02, 67.32it/s]\u001b[A\n",
            " 72% 416/581 [00:04<00:02, 69.96it/s]\u001b[A\n",
            " 73% 424/581 [00:04<00:02, 71.70it/s]\u001b[A\n",
            " 74% 432/581 [00:04<00:02, 72.03it/s]\u001b[A\n",
            " 76% 441/581 [00:05<00:01, 74.79it/s]\u001b[A\n",
            " 77% 449/581 [00:05<00:01, 74.40it/s]\u001b[A\n",
            " 79% 457/581 [00:05<00:02, 59.13it/s]\u001b[A\n",
            " 80% 464/581 [00:05<00:01, 60.35it/s]\u001b[A\n",
            " 81% 472/581 [00:05<00:01, 64.37it/s]\u001b[A\n",
            " 82% 479/581 [00:05<00:01, 61.32it/s]\u001b[A\n",
            " 84% 487/581 [00:05<00:01, 65.38it/s]\u001b[A\n",
            " 85% 494/581 [00:05<00:01, 63.05it/s]\u001b[A\n",
            " 86% 502/581 [00:06<00:01, 62.08it/s]\u001b[A\n",
            " 88% 510/581 [00:06<00:01, 66.26it/s]\u001b[A\n",
            " 89% 518/581 [00:06<00:00, 69.60it/s]\u001b[A\n",
            " 91% 526/581 [00:06<00:00, 68.62it/s]\u001b[A\n",
            " 92% 533/581 [00:06<00:00, 66.47it/s]\u001b[A\n",
            " 93% 540/581 [00:06<00:00, 55.85it/s]\u001b[A\n",
            " 94% 547/581 [00:06<00:00, 58.13it/s]\u001b[A\n",
            " 96% 555/581 [00:06<00:00, 62.13it/s]\u001b[A\n",
            " 97% 562/581 [00:06<00:00, 63.09it/s]\u001b[A\n",
            " 98% 569/581 [00:07<00:00, 58.48it/s]\u001b[A\n",
            "                                        \n",
            "\u001b[A{'eval_loss': 0.2547953426837921, 'eval_precision': 0.7640887290167866, 'eval_recall': 0.7682338758288125, 'eval_f1': 0.7661556958220619, 'eval_accuracy': 0.9283891937231329, 'eval_runtime': 7.8441, 'eval_samples_per_second': 148.009, 'eval_steps_per_second': 74.068, 'epoch': 2.0}\n",
            " 67% 9284/13926 [10:01<04:29, 17.20it/s]\n",
            "100% 581/581 [00:07<00:00, 58.92it/s]\u001b[A\n",
            "{'loss': 0.1426, 'grad_norm': 3.9273922443389893, 'learning_rate': 9.536837570012925e-06, 'epoch': 2.05}\n",
            "{'loss': 0.1158, 'grad_norm': 0.014896186999976635, 'learning_rate': 8.459715639810427e-06, 'epoch': 2.15}\n",
            "{'loss': 0.1066, 'grad_norm': 0.1639762818813324, 'learning_rate': 7.382593709607928e-06, 'epoch': 2.26}\n",
            "{'loss': 0.1192, 'grad_norm': 0.04586627706885338, 'learning_rate': 6.305471779405429e-06, 'epoch': 2.37}\n",
            "{'loss': 0.138, 'grad_norm': 0.11294171214103699, 'learning_rate': 5.22834984920293e-06, 'epoch': 2.48}\n",
            "{'loss': 0.1038, 'grad_norm': 4.616501331329346, 'learning_rate': 4.1512279190004315e-06, 'epoch': 2.59}\n",
            "{'loss': 0.1198, 'grad_norm': 0.04036308079957962, 'learning_rate': 3.0741059887979318e-06, 'epoch': 2.69}\n",
            "{'loss': 0.1067, 'grad_norm': 0.017066702246665955, 'learning_rate': 1.996984058595433e-06, 'epoch': 2.8}\n",
            "{'loss': 0.0907, 'grad_norm': 0.028899919241666794, 'learning_rate': 9.198621283929341e-07, 'epoch': 2.91}\n",
            "100% 13925/13926 [14:59<00:00, 14.62it/s]\n",
            "  0% 0/581 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 10/581 [00:00<00:06, 89.92it/s]\u001b[A\n",
            "  3% 19/581 [00:00<00:06, 85.87it/s]\u001b[A\n",
            "  5% 28/581 [00:00<00:06, 82.78it/s]\u001b[A\n",
            "  6% 37/581 [00:00<00:06, 81.88it/s]\u001b[A\n",
            "  8% 46/581 [00:00<00:06, 79.05it/s]\u001b[A\n",
            "  9% 54/581 [00:00<00:07, 72.68it/s]\u001b[A\n",
            " 11% 62/581 [00:00<00:07, 67.71it/s]\u001b[A\n",
            " 12% 69/581 [00:00<00:07, 67.74it/s]\u001b[A\n",
            " 13% 76/581 [00:01<00:08, 62.30it/s]\u001b[A\n",
            " 14% 84/581 [00:01<00:07, 65.73it/s]\u001b[A\n",
            " 16% 93/581 [00:01<00:06, 70.55it/s]\u001b[A\n",
            " 17% 101/581 [00:01<00:06, 72.80it/s]\u001b[A\n",
            " 19% 109/581 [00:01<00:07, 66.76it/s]\u001b[A\n",
            " 20% 117/581 [00:01<00:06, 69.87it/s]\u001b[A\n",
            " 22% 125/581 [00:01<00:06, 71.61it/s]\u001b[A\n",
            " 23% 133/581 [00:01<00:06, 72.16it/s]\u001b[A\n",
            " 24% 142/581 [00:01<00:05, 75.13it/s]\u001b[A\n",
            " 26% 150/581 [00:02<00:05, 75.78it/s]\u001b[A\n",
            " 27% 158/581 [00:02<00:05, 71.67it/s]\u001b[A\n",
            " 29% 166/581 [00:02<00:06, 67.26it/s]\u001b[A\n",
            " 30% 173/581 [00:02<00:06, 63.62it/s]\u001b[A\n",
            " 31% 180/581 [00:02<00:06, 64.58it/s]\u001b[A\n",
            " 32% 187/581 [00:02<00:06, 64.72it/s]\u001b[A\n",
            " 33% 194/581 [00:02<00:06, 64.31it/s]\u001b[A\n",
            " 35% 203/581 [00:02<00:05, 70.42it/s]\u001b[A\n",
            " 37% 215/581 [00:02<00:04, 82.30it/s]\u001b[A\n",
            " 39% 224/581 [00:03<00:04, 80.57it/s]\u001b[A\n",
            " 40% 235/581 [00:03<00:03, 88.49it/s]\u001b[A\n",
            " 42% 246/581 [00:03<00:03, 93.42it/s]\u001b[A\n",
            " 44% 256/581 [00:03<00:03, 86.44it/s]\u001b[A\n",
            " 46% 267/581 [00:03<00:03, 92.11it/s]\u001b[A\n",
            " 48% 278/581 [00:03<00:03, 96.27it/s]\u001b[A\n",
            " 50% 288/581 [00:03<00:03, 96.76it/s]\u001b[A\n",
            " 51% 298/581 [00:03<00:03, 92.38it/s]\u001b[A\n",
            " 53% 308/581 [00:04<00:03, 86.67it/s]\u001b[A\n",
            " 55% 318/581 [00:04<00:03, 82.37it/s]\u001b[A\n",
            " 57% 329/581 [00:04<00:02, 89.37it/s]\u001b[A\n",
            " 59% 340/581 [00:04<00:02, 94.34it/s]\u001b[A\n",
            " 60% 351/581 [00:04<00:02, 97.83it/s]\u001b[A\n",
            " 62% 361/581 [00:04<00:02, 89.88it/s]\u001b[A\n",
            " 64% 371/581 [00:04<00:02, 74.08it/s]\u001b[A\n",
            " 66% 382/581 [00:04<00:02, 80.31it/s]\u001b[A\n",
            " 67% 392/581 [00:04<00:02, 83.87it/s]\u001b[A\n",
            " 69% 402/581 [00:05<00:02, 80.89it/s]\u001b[A\n",
            " 71% 411/581 [00:05<00:02, 83.10it/s]\u001b[A\n",
            " 73% 422/581 [00:05<00:01, 90.09it/s]\u001b[A\n",
            " 75% 433/581 [00:05<00:01, 94.76it/s]\u001b[A\n",
            " 76% 443/581 [00:05<00:01, 95.81it/s]\u001b[A\n",
            " 78% 453/581 [00:05<00:01, 88.92it/s]\u001b[A\n",
            " 80% 463/581 [00:05<00:01, 82.09it/s]\u001b[A\n",
            " 81% 473/581 [00:05<00:01, 84.01it/s]\u001b[A\n",
            " 83% 482/581 [00:06<00:01, 78.57it/s]\u001b[A\n",
            " 85% 491/581 [00:06<00:01, 75.40it/s]\u001b[A\n",
            " 86% 502/581 [00:06<00:01, 75.61it/s]\u001b[A\n",
            " 88% 513/581 [00:06<00:00, 82.46it/s]\u001b[A\n",
            " 90% 524/581 [00:06<00:00, 88.16it/s]\u001b[A\n",
            " 92% 534/581 [00:06<00:00, 85.07it/s]\u001b[A\n",
            " 93% 543/581 [00:06<00:00, 70.85it/s]\u001b[A\n",
            " 95% 553/581 [00:06<00:00, 77.65it/s]\u001b[A\n",
            " 97% 563/581 [00:07<00:00, 82.53it/s]\u001b[A\n",
            " 98% 572/581 [00:07<00:00, 79.38it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.30663996934890747, 'eval_precision': 0.7694145758661888, 'eval_recall': 0.7763713080168776, 'eval_f1': 0.7728772877287728, 'eval_accuracy': 0.9274455667004509, 'eval_runtime': 7.8237, 'eval_samples_per_second': 148.395, 'eval_steps_per_second': 74.261, 'epoch': 3.0}\n",
            "100% 13926/13926 [15:07<00:00, 14.62it/s]\n",
            "100% 581/581 [00:07<00:00, 76.78it/s]\u001b[A\n",
            "{'train_runtime': 920.1182, 'train_samples_per_second': 30.27, 'train_steps_per_second': 15.135, 'train_loss': 0.18803880202022072, 'epoch': 3.0}\n",
            "100% 13926/13926 [15:20<00:00, 15.13it/s]\n",
            "100% 581/581 [00:10<00:00, 53.14it/s]\n",
            "\n",
            "--- Test Set Metrics ---\n",
            "F1-score: 0.7731\n",
            "Accuracy: 0.9315\n",
            "Precision: 0.7809\n",
            "Recall: 0.7656\n",
            "\n",
            "âœ… Training complete! Time taken: 15.84 minutes\n",
            "\n",
            "ðŸ“ Files saved in: data/finbert_ner_results/\n",
            "  - checkpoint-9284\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# ðŸ§  FinBERT NER TRAINING RUN\n",
        "# ============================\n",
        "\n",
        "import torch, os, time\n",
        "\n",
        "# --- 1ï¸âƒ£ Confirm GPU / CPU ---\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Training will run on: {device.upper()}\")\n",
        "\n",
        "# --- 2ï¸âƒ£ Change directory to your repo ---\n",
        "%cd /content/drive/MyDrive/Finance-Insight\n",
        "\n",
        "# --- 3ï¸âƒ£ Check that your training script exists ---\n",
        "train_path = \"scripts/7_train_quick_ner.py\"\n",
        "if os.path.exists(train_path):\n",
        "    print(f\"âœ… Found training script: {train_path}\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"âŒ {train_path} not found! Check folder path.\")\n",
        "\n",
        "# --- 4ï¸âƒ£ Create results folder (auto-saves to Drive) ---\n",
        "os.makedirs(\"data/finbert_ner_results\", exist_ok=True)\n",
        "print(\"ðŸ“‚ Output dir ready:\", \"data/finbert_ner_results\")\n",
        "\n",
        "# --- 5ï¸âƒ£ Start training ---\n",
        "print(\"\\nðŸ§© Starting FinBERT NER fine-tuning...\\n\")\n",
        "start = time.time()\n",
        "\n",
        "!python scripts/7_train_quick_ner.py\n",
        "\n",
        "print(\"\\nâœ… Training complete! Time taken: {:.2f} minutes\".format((time.time()-start)/60))\n",
        "\n",
        "# --- 6ï¸âƒ£ Show saved files ---\n",
        "print(\"\\nðŸ“ Files saved in: data/finbert_ner_results/\")\n",
        "for f in os.listdir(\"data/finbert_ner_results\"):\n",
        "    print(\"  -\", f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "OAzAdARzCXfe",
        "outputId": "dfbe84d8-687d-450c-ff2f-a724b38d464a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_metrics\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Metric\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Accuracy\",\n          \"Recall\",\n          \"F1-score\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07939611136573378,\n        \"min\": 0.7656,\n        \"max\": 0.9315,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9315,\n          0.7656,\n          0.7731\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_metrics"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-43167ddf-e416-4396-ac2f-6bb55e2735f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>F1-score</td>\n",
              "      <td>0.7731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Accuracy</td>\n",
              "      <td>0.9315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Precision</td>\n",
              "      <td>0.7809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Recall</td>\n",
              "      <td>0.7656</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43167ddf-e416-4396-ac2f-6bb55e2735f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-43167ddf-e416-4396-ac2f-6bb55e2735f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-43167ddf-e416-4396-ac2f-6bb55e2735f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-328fe32e-0fe4-4899-982a-868a05c564d9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-328fe32e-0fe4-4899-982a-868a05c564d9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-328fe32e-0fe4-4899-982a-868a05c564d9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_e3d6cb5e-ccc7-4d77-bb50-992aa8a71eeb\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_metrics')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e3d6cb5e-ccc7-4d77-bb50-992aa8a71eeb button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_metrics');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      Metric   Score\n",
              "0   F1-score  0.7731\n",
              "1   Accuracy  0.9315\n",
              "2  Precision  0.7809\n",
              "3     Recall  0.7656"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# your metrics\n",
        "metrics = {\n",
        "    \"Metric\": [\"F1-score\", \"Accuracy\", \"Precision\", \"Recall\"],\n",
        "    \"Score\": [0.7731, 0.9315, 0.7809, 0.7656]\n",
        "}\n",
        "\n",
        "df_metrics = pd.DataFrame(metrics)\n",
        "df_metrics.style.set_caption(\"FinBERT NER - Test Set Metrics\").set_table_styles([\n",
        "    {\"selector\": \"caption\", \"props\": [(\"font-size\", \"16px\"), (\"font-weight\", \"bold\"), (\"color\", \"#2E86C1\")]}\n",
        "])\n",
        "display(df_metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dBV-ezw8oay"
      },
      "outputs": [],
      "source": [
        "df_metrics.to_csv(\"/content/drive/MyDrive/Finance-Insight/data/finbert_ner_results/test_metrics.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2cUosMi-OWo",
        "outputId": "97254ac2-5369-4103-f300-a07369deb7ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "01_test_ner.ipynb  data  notebooks  README.md  requirements.txt  scripts\n"
          ]
        }
      ],
      "source": [
        "!ls /content/repo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFrlO-tpFy0b",
        "outputId": "83f9178e-65b3-4421-dca2-50f24bf97ede"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo exists: True\n",
            "Repo top-level: ['.gitignore', '01_test_ner.ipynb', 'scripts', 'data', '.git', 'README.md', 'notebooks', 'requirements.txt']\n",
            "Results src: True\n",
            "Results dst: True\n"
          ]
        }
      ],
      "source": [
        "# confirm paths\n",
        "import os\n",
        "print(\"Repo exists:\", os.path.exists(\"/content/repo\"))\n",
        "print(\"Repo top-level:\", os.listdir(\"/content/repo\")[:20] if os.path.exists(\"/content/repo\") else \"NA\")\n",
        "print(\"Results src:\", os.path.exists(\"/content/drive/MyDrive/Finance-Insight/data/finbert_ner_results\"))\n",
        "print(\"Results dst:\", os.path.exists(\"/content/repo/data/finbert_ner_results\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsKcH3Z1F5gp",
        "outputId": "c73085cc-c602-49b8-d3dc-0c4af003cf47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Copied results to repo/data/finbert_ner_results\n"
          ]
        }
      ],
      "source": [
        "import os, shutil\n",
        "SRC = \"/content/drive/MyDrive/Finance-Insight/data/finbert_ner_results\"\n",
        "DST = \"/content/repo/data/finbert_ner_results\"\n",
        "\n",
        "if os.path.realpath(SRC) != os.path.realpath(DST):\n",
        "    if os.path.exists(DST):\n",
        "        shutil.rmtree(DST)\n",
        "    shutil.copytree(SRC, DST)\n",
        "    print(\"âœ… Copied results to repo/data/finbert_ner_results\")\n",
        "else:\n",
        "    print(\"âš ï¸ Source and destination are the same â€” no copy needed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laqMESilvX7x",
        "outputId": "645b6aef-2bf8-4683-9b28-503b31635e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste your GitHub PAT (input hidden): Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Repo dir ok: /content/repo\n",
            "Results folder exists: False\n",
            "Commit exit code (0 means commit created): 0\n",
            "Trying to push to 'main' branch...\n",
            "âœ… Pushed to GitHub (main/master). Check your repo now.\n"
          ]
        }
      ],
      "source": [
        "# âœ… Commit & push results + notebook from /content/repo to GitHub\n",
        "from getpass import getpass\n",
        "import os, sys\n",
        "\n",
        "REPO_DIR = \"/content/repo\"\n",
        "GITHUB_REPO = \"Suryasnata1404/Finance-Insight\"  # keep as is\n",
        "\n",
        "# ask for PAT securely\n",
        "token = getpass(\"Paste your GitHub PAT (input hidden): \")\n",
        "\n",
        "# basic safety checks\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    raise SystemExit(\"âŒ /content/repo not found. Clone first.\")\n",
        "print(\"Repo dir ok:\", REPO_DIR)\n",
        "\n",
        "# set git user (local to this clone)\n",
        "os.system(f'git -C \"{REPO_DIR}\" config user.email \"you@example.com\"')\n",
        "os.system(f'git -C \"{REPO_DIR}\" config user.name \"Your Name\"')\n",
        "\n",
        "# set authenticated origin using token (temporarily)\n",
        "push_url = f\"https://{token}@github.com/{GITHUB_REPO}.git\"\n",
        "os.system(f'git -C \"{REPO_DIR}\" remote remove origin 2>/dev/null || true')\n",
        "os.system(f'git -C \"{REPO_DIR}\" remote add origin {push_url}')\n",
        "\n",
        "# ensure results folder is present\n",
        "results_path = os.path.join(REPO_DIR, \"data\", \"finbert_ner_results\")\n",
        "print(\"Results folder exists:\", os.path.exists(results_path))\n",
        "\n",
        "# add files (force in case .gitignore blocks them)\n",
        "os.system(f'git -C \"{REPO_DIR}\" add data/finbert_ner_results -f')\n",
        "os.system(f'git -C \"{REPO_DIR}\" add 01_test_ner.ipynb -f')\n",
        "\n",
        "# commit\n",
        "ret = os.system(f'git -C \"{REPO_DIR}\" commit -m \"Add FinBERT NER results and notebook\" || true')\n",
        "print(\"Commit exit code (0 means commit created):\", ret)\n",
        "\n",
        "# push: try main, then master\n",
        "print(\"Trying to push to 'main' branch...\")\n",
        "ret = os.system(f'git -C \"{REPO_DIR}\" push origin main || git -C \"{REPO_DIR}\" push origin master')\n",
        "if ret == 0:\n",
        "    print(\"âœ… Pushed to GitHub (main/master). Check your repo now.\")\n",
        "else:\n",
        "    print(\"âš ï¸ Push returned non-zero. If protected-branch rules exist, please push from your local machine (VSCode).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8dbf640741584c7e90cfe8e06b15744d",
            "10a2be342df542a9aaa3ba4287e5935e",
            "2b5b0357b8104486ae8ef187ef222f10",
            "7ac28b2dabc142b094ee82445cb0d0e6",
            "4ee064c177eb4019b060657e380eee84",
            "348cc4e2c2424a4b97f186b0289798ed",
            "e372ea4130ad4242bffd008ecb707973",
            "f88bcf477d954762999cbd2564688d0a",
            "4889e80855d94e7188e609c79cbe2cfe",
            "0aebc4913c224f468cd82ed3e07b0660",
            "29678a557ff245c8a154142a6aeeb4a0",
            "9b65916548844a5ea2f6fd78350cb8c1",
            "1478ef20576144738fab973b87efce5f",
            "c3388b9830fb4009a0d97aa8773ce972",
            "a56cc28f00074585bcda913686bfbec9",
            "c348e8f7479a4f66bad3d9f7deda47d2",
            "d569466312f54cf1a5bbe4957b3061bd",
            "ea9fb3ffce714b9eb2741123565e7440",
            "236ed33de4784713bd49d79329b6d44c",
            "66d473713de7414ab436bc8dd5e64e6e",
            "184bd4f7e3f24a8a88f8bcfb7a17cf71",
            "e930c4dc12c446478e22d13a6936604b",
            "9eb02f2f5e35436989f7caeb75e42017",
            "b88dfaa5165b450e963060273a11c79b",
            "ed6f5fe0c68c4905bfa9c7774b470a33",
            "e37a68362d3d44439abf8fb8dc7ecedc",
            "940f6cf27dc744418a6e2fdb02f5a5e9",
            "c5f17d90d4bc4d5481d8c45ea2b461a0",
            "fac52d14256c47dcb5f8fee97efd9402",
            "8221bfa14ec047ee9a1c26deae236a1c",
            "1081fb796af642118aad5fd3c119f833",
            "319bc161f1fc45b2beea125c616875f6",
            "5bfded1be3bb44ab8ac23009717c21e6"
          ]
        },
        "id": "bUjO4y-HvlHV",
        "outputId": "1d37fdb8-b797-4428-a721-c3f966385f9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Loaded dataset and label map\n",
            "   Train: 9284 samples\n",
            "   Validation: 1161 samples\n",
            "   Test: 1161 samples\n",
            "\n",
            "Calculating class weights from training data...\n",
            "\n",
            "Label distribution in training data:\n",
            "  B-DATE          (ID 0):  12249 ( 3.98%)\n",
            "  B-FIN_TERM      (ID 1):    289 ( 0.09%)\n",
            "  B-FIN_VALUE     (ID 2):   1217 ( 0.40%)\n",
            "  B-ORG           (ID 3):  11404 ( 3.70%)\n",
            "  I-DATE          (ID 4):  25640 ( 8.33%)\n",
            "  I-FIN_TERM      (ID 5):    319 ( 0.10%)\n",
            "  I-FIN_VALUE     (ID 6):   1418 ( 0.46%)\n",
            "  I-ORG           (ID 7):   9461 ( 3.07%)\n",
            "  O               (ID 8): 245914 (79.87%)\n",
            "\n",
            "âœ… Calculated class weights (higher = more important):\n",
            "  B-DATE         : 0.7835\n",
            "  B-FIN_TERM     : 33.2081\n",
            "  B-FIN_VALUE    : 7.8859\n",
            "  B-ORG          : 0.8416\n",
            "  I-DATE         : 0.3743\n",
            "  I-FIN_TERM     : 30.0851\n",
            "  I-FIN_VALUE    : 6.7681\n",
            "  I-ORG          : 1.0144\n",
            "  O              : 0.0390\n",
            "\n",
            "âš ï¸  FIN_TERM weights: B-FIN_TERM=33.2081, I-FIN_TERM=30.0851\n",
            "   O weight: 0.0390 (B-FIN_TERM is 850.9x more important)\n",
            "Tokenizing dataset...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8dbf640741584c7e90cfe8e06b15744d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/9284 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b65916548844a5ea2f6fd78350cb8c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1161 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9eb02f2f5e35436989f7caeb75e42017",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1161 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Dataset tokenized\n",
            "\n",
            "Using device: cuda\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
            "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([9, 768]) in the model instantiated\n",
            "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([9]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1531652212.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "ðŸš€ STARTING TRAINING WITH CLASS WEIGHTS\n",
            "================================================================================\n",
            "This will retrain the model with higher weights for FIN_TERM\n",
            "This should significantly improve FIN_TERM detection!\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11181' max='13926' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11181/13926 42:15 < 10:22, 4.41 it/s, Epoch 2.41/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.299700</td>\n",
              "      <td>0.399667</td>\n",
              "      <td>0.457211</td>\n",
              "      <td>0.766995</td>\n",
              "      <td>0.572908</td>\n",
              "      <td>0.846974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.308200</td>\n",
              "      <td>0.410376</td>\n",
              "      <td>0.615150</td>\n",
              "      <td>0.813506</td>\n",
              "      <td>0.700558</td>\n",
              "      <td>0.905017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13926' max='13926' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13926/13926 53:00, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.299700</td>\n",
              "      <td>0.399667</td>\n",
              "      <td>0.457211</td>\n",
              "      <td>0.766995</td>\n",
              "      <td>0.572908</td>\n",
              "      <td>0.846974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.308200</td>\n",
              "      <td>0.410376</td>\n",
              "      <td>0.615150</td>\n",
              "      <td>0.813506</td>\n",
              "      <td>0.700558</td>\n",
              "      <td>0.905017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.200400</td>\n",
              "      <td>0.517217</td>\n",
              "      <td>0.651280</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.721102</td>\n",
              "      <td>0.912764</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… Training complete with class weights!\n",
            "ðŸ“ Model saved to: /content/drive/MyDrive/Finance-Insight/data/finbert_ner_weighted\n",
            "\n",
            "================================================================================\n",
            "EVALUATING ON TEST SET\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== SeqEval classification report (test set) - AFTER FIX ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        DATE     0.8371    0.9294    0.8808      1161\n",
            "    FIN_TERM     0.0663    0.3438    0.1111        32\n",
            "   FIN_VALUE     0.6409    0.8198    0.7194       172\n",
            "         ORG     0.4960    0.6739    0.5714       834\n",
            "\n",
            "   micro avg     0.6385    0.8154    0.7162      2199\n",
            "   macro avg     0.5101    0.6917    0.5707      2199\n",
            "weighted avg     0.6812    0.8154    0.7396      2199\n",
            "\n",
            "\n",
            "âœ… FIN_TERM should now have improved scores!\n",
            "   Compare these results with the previous 0.0000 scores.\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# âœ… COMPLETE FIX FOR FIN_TERM: Retrain with Class Weights\n",
        "# ============================================\n",
        "# This will fix the FIN_TERM issue by retraining with balanced class weights\n",
        "\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForTokenClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForTokenClassification\n",
        ")\n",
        "from datasets import load_dataset\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import evaluate # Import evaluate library\n",
        "from seqeval.metrics import classification_report # Import classification_report here\n",
        "\n",
        "# ============================================\n",
        "# STEP 1: Load Dataset and Label Map\n",
        "# ============================================\n",
        "DATA_DIR = \"/content/drive/MyDrive/Finance-Insight/data/processed/ner_auto_splits\"\n",
        "\n",
        "dataset = load_dataset(\n",
        "    \"json\",\n",
        "    data_files={\n",
        "        \"train\": os.path.join(DATA_DIR, \"train.jsonl\"),\n",
        "        \"validation\": os.path.join(DATA_DIR, \"validation.jsonl\"),\n",
        "        \"test\": os.path.join(DATA_DIR, \"test.jsonl\")\n",
        "    }\n",
        ")\n",
        "\n",
        "with open(os.path.join(DATA_DIR, \"label_map.json\"), \"r\") as f:\n",
        "    label_info = json.load(f)\n",
        "label2id = label_info[\"label2id\"]\n",
        "id2label = {int(k): v for k, v in label_info[\"id2label\"].items()}\n",
        "\n",
        "# Create label list for seqeval\n",
        "label_list = [id2label[i] for i in sorted(id2label.keys())]\n",
        "\n",
        "print(\"âœ… Loaded dataset and label map\")\n",
        "print(f\"   Train: {len(dataset['train'])} samples\")\n",
        "print(f\"   Validation: {len(dataset['validation'])} samples\")\n",
        "print(f\"   Test: {len(dataset['test'])} samples\\n\")\n",
        "\n",
        "# ============================================\n",
        "# STEP 2: Calculate Class Weights\n",
        "# ============================================\n",
        "print(\"Calculating class weights from training data...\")\n",
        "all_labels = []\n",
        "for sample in dataset[\"train\"]:\n",
        "    # Exclude -100 (ignored tokens)\n",
        "    all_labels.extend([tag for tag in sample[\"ner_tags\"] if tag != -100])\n",
        "\n",
        "\n",
        "label_counts = Counter(all_labels)\n",
        "total_samples = len(all_labels)\n",
        "num_classes = len(label2id)\n",
        "\n",
        "print(f\"\\nLabel distribution in training data:\")\n",
        "for label_id in sorted(label_counts.keys()):\n",
        "    label_name = id2label.get(label_id, f\"ID_{label_id}\")\n",
        "    count = label_counts[label_id]\n",
        "    percentage = (count / total_samples) * 100\n",
        "    print(f\"  {label_name:15s} (ID {label_id}): {count:6d} ({percentage:5.2f}%)\")\n",
        "\n",
        "# Calculate class weights (inverse frequency weighting)\n",
        "class_weights = torch.zeros(num_classes)\n",
        "# Ensure all labels from 0 to num_classes-1 are considered, even if not in label_counts\n",
        "for label_id in range(num_classes):\n",
        "    count = label_counts.get(label_id, 0) # Get count, default to 0 if label_id not in counts\n",
        "    if count > 0:\n",
        "        # Higher weight for rare classes (like FIN_TERM)\n",
        "        class_weights[label_id] = total_samples / (num_classes * count)\n",
        "    else:\n",
        "        # Assign a default weight (e.g., 1.0 or average) for classes not in training data\n",
        "        # Using 1.0 might be too low, let's use the mean of existing weights or a sensible default\n",
        "        # For now, let's use 1.0, but be aware this might need tuning if some classes are truly missing\n",
        "        class_weights[label_id] = 1.0\n",
        "\n",
        "\n",
        "# Normalize weights\n",
        "class_weights = class_weights / class_weights.mean() * num_classes\n",
        "\n",
        "print(f\"\\nâœ… Calculated class weights (higher = more important):\")\n",
        "for label_id in range(num_classes):\n",
        "    label_name = id2label.get(label_id, f\"ID_{label_id}\")\n",
        "    print(f\"  {label_name:15s}: {class_weights[label_id]:.4f}\")\n",
        "\n",
        "# Show FIN_TERM weights specifically\n",
        "# Ensure the label IDs for FIN_TERM exist in label2id before accessing\n",
        "fin_term_b_id = label2id.get(\"B-FIN_TERM\")\n",
        "fin_term_i_id = label2id.get(\"I-FIN_TERM\")\n",
        "o_id = label2id.get(\"O\")\n",
        "\n",
        "if fin_term_b_id is not None and fin_term_i_id is not None and o_id is not None:\n",
        "    fin_term_weight_b = class_weights[fin_term_b_id]\n",
        "    fin_term_weight_i = class_weights[fin_term_i_id]\n",
        "    o_weight = class_weights[o_id]\n",
        "    print(f\"\\nâš ï¸  FIN_TERM weights: B-FIN_TERM={fin_term_weight_b:.4f}, I-FIN_TERM={fin_term_weight_i:.4f}\")\n",
        "    if o_weight > 0:\n",
        "         print(f\"   O weight: {o_weight:.4f} (B-FIN_TERM is {fin_term_weight_b/o_weight:.1f}x more important)\")\n",
        "    else:\n",
        "        print(f\"   O weight: {o_weight:.4f}\")\n",
        "else:\n",
        "    print(\"\\nWarning: Could not find all FIN_TERM or O labels in label map to show specific weights.\")\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# STEP 3: Tokenize Dataset\n",
        "# ============================================\n",
        "MODEL_NAME = \"ProsusAI/finbert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"],\n",
        "        truncation=True,\n",
        "        is_split_into_words=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                # Only label the first token of a word\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                label_ids.append(-100) # Set subsequent tokens of a word to -100\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "print(\"Tokenizing dataset...\")\n",
        "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)\n",
        "print(\"âœ… Dataset tokenized\\n\")\n",
        "\n",
        "# ============================================\n",
        "# STEP 4: Create Weighted Trainer and Metric Computation\n",
        "# ============================================\n",
        "class WeightedTrainer(Trainer):\n",
        "    \"\"\"Custom Trainer with class-weighted loss\"\"\"\n",
        "    def __init__(self, class_weights, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        # Ensure class_weights are on the correct device\n",
        "        self.class_weights = class_weights.to(self.args.device)\n",
        "\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        \"\"\"Compute loss with class weights, accepting additional kwargs for compatibility\"\"\"\n",
        "        labels = inputs.get(\"labels\")\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        # Use weighted CrossEntropyLoss\n",
        "        # Ensure weights are on the same device as logits and labels\n",
        "        loss_fct = nn.CrossEntropyLoss(weight=self.class_weights, ignore_index=-100)\n",
        "\n",
        "        # Only compute loss on active labels\n",
        "        active_loss = labels.view(-1) != -100\n",
        "        active_logits = logits.view(-1, self.model.config.num_labels)\n",
        "        active_labels = torch.where(\n",
        "            active_loss,\n",
        "            labels.view(-1),\n",
        "            torch.tensor(loss_fct.ignore_index).type_as(labels)\n",
        "        )\n",
        "        loss = loss_fct(active_logits, active_labels)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Define metric computation function\n",
        "seqeval = evaluate.load(\"seqeval\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (usually -100)\n",
        "    true_predictions = [\n",
        "        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    # Corrected scheme name to uppercase \"IOB2\"\n",
        "    results = seqeval.compute(predictions=true_predictions, references=true_labels, scheme=\"IOB2\", mode=\"strict\")\n",
        "    # Return a dictionary of metrics\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# STEP 5: Load Model and Setup Training\n",
        "# ============================================\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\\n\")\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=len(label2id),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True  # Fix: Ignore size mismatch for classifier layer\n",
        ").to(device)\n",
        "\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/Finance-Insight/data/finbert_ner_weighted\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=100,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\", # Use the 'f1' computed by compute_metrics\n",
        "    greater_is_better=True,\n",
        "    report_to=\"none\",\n",
        "    dataloader_num_workers=2 # Added for potentially faster data loading\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "\n",
        "# ============================================\n",
        "# STEP 6: Create and Train Weighted Trainer\n",
        "# ============================================\n",
        "trainer = WeightedTrainer(\n",
        "    class_weights=class_weights,\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"], # Corrected to access the train split\n",
        "    eval_dataset=tokenized_dataset[\"validation\"], # Corrected to access the validation split\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics # Pass the compute_metrics function\n",
        ")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"ðŸš€ STARTING TRAINING WITH CLASS WEIGHTS\")\n",
        "print(\"=\" * 80)\n",
        "print(\"This will retrain the model with higher weights for FIN_TERM\")\n",
        "print(\"This should significantly improve FIN_TERM detection!\\n\")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\nâœ… Training complete with class weights!\")\n",
        "print(\"ðŸ“ Model saved to:\", training_args.output_dir)\n",
        "\n",
        "# ============================================\n",
        "# STEP 7: Evaluate on Test Set\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"EVALUATING ON TEST SET\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Run predictions on test set\n",
        "predictions = trainer.predict(tokenized_dataset[\"test\"])\n",
        "pred_ids = np.argmax(predictions.predictions, axis=-1)\n",
        "\n",
        "# Convert to label sequences for seqeval\n",
        "def ids_to_label_seqs(pred_array, label_id_array):\n",
        "    pred_seqs = []\n",
        "    true_seqs = []\n",
        "    for p_row, t_row in zip(pred_array, label_id_array):\n",
        "        p_list = []\n",
        "        t_list = []\n",
        "        for p, t in zip(p_row, t_row):\n",
        "            # Only include tokens that were not ignored (-100)\n",
        "            if int(t) != -100:\n",
        "                p_list.append(id2label.get(int(p), \"O\")) # Get label name from ID\n",
        "                t_list.append(id2label.get(int(t), \"O\")) # Get label name from ID\n",
        "        if p_list: # Only append if there are actual tokens to evaluate\n",
        "            pred_seqs.append(p_list)\n",
        "            true_seqs.append(t_list)\n",
        "    return pred_seqs, true_seqs\n",
        "\n",
        "pred_label_seqs, true_label_seqs = ids_to_label_seqs(pred_ids, predictions.label_ids)\n",
        "\n",
        "print(\"\\n=== SeqEval classification report (test set) - AFTER FIX ===\")\n",
        "# Ensure the label list used for the report matches the labels present in the data\n",
        "# and is sorted correctly.\n",
        "# seqeval.metrics.classification_report expects a list of label names.\n",
        "# We can use the label_list created earlier, excluding -100 if it was implicitly included.\n",
        "report_labels = [label for label in label_list if label != \"-100\"] # Ensure -100 is not in labels\n",
        "\n",
        "# Check if any of the true labels are not in report_labels and add them if necessary\n",
        "all_true_labels_in_test = set(tag for seq in true_label_seqs for tag in seq)\n",
        "for label in all_true_labels_in_test:\n",
        "    if label not in report_labels:\n",
        "        report_labels.append(label)\n",
        "\n",
        "# Sort the report_labels based on their original ID order\n",
        "report_labels.sort(key=lambda x: label2id.get(x, float('inf'))) # Use get with inf for labels not in original map\n",
        "\n",
        "print(classification_report(true_label_seqs, pred_label_seqs, digits=4, zero_division=0)) # Added zero_division=0\n",
        "\n",
        "print(\"\\nâœ… FIN_TERM should now have improved scores!\")\n",
        "print(\"   Compare these results with the previous 0.0000 scores.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "PWGKwEIbQ25J",
        "outputId": "16072705-7c98-4f33-c9c4-88f638563404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using MODEL_DIR: /content/drive/MyDrive/Finance-Insight/data/finbert_ner_weighted\n",
            "Using DATA_DIR: /content/repo/data/processed/ner_auto_splits\n",
            "train.jsonl exists: True size: 5504055\n",
            "validation.jsonl exists: True size: 519794\n",
            "test.jsonl exists: True size: 442844\n",
            "label_map.json exists: True size: 388\n",
            "Loaded label map. Num labels: 9\n",
            "Sample id2label: {0: 'B-DATE', 1: 'B-FIN_TERM', 2: 'B-FIN_VALUE', 3: 'B-ORG', 4: 'I-DATE', 5: 'I-FIN_TERM', 6: 'I-FIN_VALUE', 7: 'I-ORG', 8: 'O'}\n",
            "Could not load from fine-tuned directory: stat: path should be string, bytes, os.PathLike or integer, not NoneType\n",
            "Attempting to load tokenizer from base model: ProsusAI/finbert\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "stat: path should be string, bytes, os.PathLike or integer, not NoneType",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1734425326.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# Try loading from the fine-tuned model directory first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForTokenClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"âœ… Model and tokenizer loaded from fine-tuned directory: {MODEL_DIR}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muse_fast\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2095\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"loading file {file_path} from cache at {resolved_vocab_files[file_id]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2097\u001b[0;31m         return cls._from_pretrained(\n\u001b[0m\u001b[1;32m   2098\u001b[0m             \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2133\u001b[0m         \u001b[0;31m# loaded directly from the GGUF file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfrom_slow\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_tokenizer_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslow_tokenizer_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgguf_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2135\u001b[0;31m             slow_tokenizer = (cls.slow_tokenizer_class)._from_pretrained(\n\u001b[0m\u001b[1;32m   2136\u001b[0m                 \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2137\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2341\u001b[0m         \u001b[0;31m# Instantiate the tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2343\u001b[0;31m             \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2344\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mimport_protobuf_decode_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2345\u001b[0m             logger.info(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_file, do_lower_case, do_basic_tokenize, never_split, unk_token, sep_token, pad_token, cls_token, mask_token, tokenize_chinese_chars, strip_accents, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     ):\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             raise ValueError(\n\u001b[1;32m    116\u001b[0m                 \u001b[0;34mf\"Can't find a vocabulary file at path '{vocab_file}'. To load the vocabulary from a Google pretrained\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/genericpath.py\u001b[0m in \u001b[0;36misfile\u001b[0;34m(path)\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: stat: path should be string, bytes, os.PathLike or integer, not NoneType"
          ]
        }
      ],
      "source": [
        "# Cell 2 â€” Set and check paths (edit if your files are elsewhere)\n",
        "import os\n",
        "import json\n",
        "import sys\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Prefer these two canonical paths â€” change if different\n",
        "REPO_DIR = \"/content/repo\"   # repo if cloned into /content/repo\n",
        "DRIVE_BASE = \"/content/drive/MyDrive/Finance-Insight\"  # your Drive copy\n",
        "# Where training splits live (use whichever exists)\n",
        "CANDIDATES = [\n",
        "    os.path.join(REPO_DIR, \"data/processed/ner_auto_splits\"),\n",
        "    os.path.join(DRIVE_BASE, \"data/processed/ner_auto_splits\"),\n",
        "    os.path.join(DRIVE_BASE, \"data/ner_auto_splits\"),\n",
        "    os.path.join(REPO_DIR, \"data/ner_auto_splits\"),\n",
        "]\n",
        "\n",
        "DATA_DIR = None\n",
        "for c in CANDIDATES:\n",
        "    if os.path.exists(c):\n",
        "        DATA_DIR = c\n",
        "        break\n",
        "if DATA_DIR is None:\n",
        "    raise FileNotFoundError(\"Couldn't find ner_auto_splits in expected locations. Update CANDIDATES.\")\n",
        "\n",
        "\n",
        "# Explicitly set the model directory to the known correct path\n",
        "MODEL_DIR = os.path.join(DRIVE_BASE, \"data/finbert_ner_weighted\")\n",
        "\n",
        "\n",
        "print(\"Using MODEL_DIR:\", MODEL_DIR)\n",
        "print(\"Using DATA_DIR:\", DATA_DIR)\n",
        "# quick file checks\n",
        "for fname in (\"train.jsonl\",\"validation.jsonl\",\"test.jsonl\",\"label_map.json\"):\n",
        "    p = os.path.join(DATA_DIR, fname)\n",
        "    print(fname, \"exists:\", os.path.exists(p), \"size:\", os.path.getsize(p) if os.path.exists(p) else \"NA\")\n",
        "\n",
        "# Load label map\n",
        "label_map_path = os.path.join(DATA_DIR, \"label_map.json\")\n",
        "with open(label_map_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    label_map = json.load(f)\n",
        "\n",
        "id2label = {}\n",
        "if isinstance(label_map, dict) and \"id2label\" in label_map:\n",
        "    id2label = {int(k): v for k, v in label_map[\"id2label\"].items()}\n",
        "elif isinstance(label_map, dict) and \"label2id\" in label_map:\n",
        "    label2id = label_map[\"label2id\"]\n",
        "    id2label = {int(v): k for k, v in label2id.items()}\n",
        "else:\n",
        "    found = False\n",
        "    for k, v in label_map.items():\n",
        "        if isinstance(v, dict) and \"id\" in v:\n",
        "            id2label[int(v[\"id\"])] = k\n",
        "            found = True\n",
        "    if not found:\n",
        "        try:\n",
        "            id2label = {int(k): v for k, v in label_map.items()}\n",
        "        except Exception:\n",
        "            raise RuntimeError(\"Unrecognized label_map.json format. Inspect file: \" + label_map_path)\n",
        "\n",
        "print(\"Loaded label map. Num labels:\", len(id2label))\n",
        "print(\"Sample id2label:\", dict(list(id2label.items())[:12]))\n",
        "\n",
        "\n",
        "# Load tokenizer and model\n",
        "BASE_MODEL = \"ProsusAI/finbert\" # Assuming the base model is FinBERT\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "try:\n",
        "    # Try loading from the fine-tuned model directory first\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, use_fast=True)\n",
        "    model = AutoModelForTokenClassification.from_pretrained(MODEL_DIR).to(DEVICE)\n",
        "    print(f\"âœ… Model and tokenizer loaded from fine-tuned directory: {MODEL_DIR}\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not load from fine-tuned directory: {e}\")\n",
        "    print(f\"Attempting to load tokenizer from base model: {BASE_MODEL}\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=True)\n",
        "    # You would typically load the fine-tuned model, so the above error indicates an issue.\n",
        "    # If you intended to use the base model for some reason, load it here:\n",
        "    # model = AutoModelForTokenClassification.from_pretrained(BASE_MODEL).to(DEVICE)\n",
        "    raise # Re-raise the original error as loading the fine-tuned model is the goal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dxEgCffVoAB",
        "outputId": "670790c4-4d52-4a61-e690-e996dbe25895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Loaded model from: /content/drive/MyDrive/Finance-Insight/data/finbert_ner_weighted/checkpoint-9284\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "MODEL_DIR = \"/content/drive/MyDrive/Finance-Insight/data/finbert_ner_weighted\"\n",
        "CHECKPOINT_DIR = os.path.join(MODEL_DIR, \"checkpoint-9284\")\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT_DIR, use_fast=True)\n",
        "model = AutoModelForTokenClassification.from_pretrained(CHECKPOINT_DIR)\n",
        "\n",
        "print(f\"âœ… Loaded model from: {CHECKPOINT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356,
          "referenced_widgets": [
            "e6cc996c83bb40c98e95719d949abb76",
            "b74f61e70477417e95567f6272516a4a",
            "a43adf59c6ff4d219fc0977e0c383883",
            "577416a876534922b70c7536badd0122",
            "fe0e0cc1a91d4b4893c40500b4c72713",
            "4be57b662cfa4bba89016f4a6f6474bd",
            "6cae79e7036a4e5ea0e8dde6bfefa8aa",
            "e0d360db81a64672a3b44d598e61ba33",
            "17356bdbb44142b7851462890f8792a5",
            "fb3e7b73c4cf442685858e62ad4e295a",
            "c8bfda41da6d4613938c2953d257053e",
            "37daae0c1cf24fd7a94f6d00930ad329",
            "54b7c8ba551948ff917d2b07eee1d631",
            "ef16c7d876e942a0b9e9361110ae0e06",
            "66510a5436f74fd0a0c1edcfab46d1c3",
            "a7763f86ce51498ab02c856c503a0be6",
            "6caa00636b334b75b1b8d06307fd6fa5",
            "1a5352a6190249f79446b71f9e087813",
            "f27d2ef2186e425c8b5d6234c62286c1",
            "d6fa4bcc93a84ab48cd3ad347aa7e8f9",
            "fb7a03ceba7148578695389b19379162",
            "1ff2ffeb2ab24c2b8dda88abe1ba7e50",
            "99fbc9928f3948a1aaa8c842b1c52364",
            "b6b455ce9a8a43d495ecc17a6c54be3d",
            "bbc4d495899744138dfa95452ba0bf64",
            "2a3d9f72db274c818bf9f94ee89973ab",
            "2e652a70f44c489aad07aafd53d76118",
            "5a830a34ff9343e597073f198e27f9c2",
            "9d1add1328094d53a7097bae76b31ada",
            "828820ad98e141e1bb72dc46a5128bb5",
            "4d21d03c99d946568b26115bbf04efe3",
            "5cc7c19373b844349a97bf23f8dd0603",
            "b6eccd2b148b466fb7c7d42821ae9065"
          ]
        },
        "id": "ZgDpxbJTWKki",
        "outputId": "decb1f87-79bd-432b-a92b-32ec4d011028"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6cc996c83bb40c98e95719d949abb76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37daae0c1cf24fd7a94f6d00930ad329",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99fbc9928f3948a1aaa8c842b1c52364",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['tokens', 'ner_tags', 'text'],\n",
            "        num_rows: 9284\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['tokens', 'ner_tags', 'text'],\n",
            "        num_rows: 1161\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['tokens', 'ner_tags', 'text'],\n",
            "        num_rows: 1161\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/Finance-Insight/data/processed/ner_auto_splits\"\n",
        "\n",
        "dataset = load_dataset(\n",
        "    \"json\",\n",
        "    data_files={\n",
        "        \"train\": os.path.join(DATA_DIR, \"train.jsonl\"),\n",
        "        \"validation\": os.path.join(DATA_DIR, \"validation.jsonl\"),\n",
        "        \"test\": os.path.join(DATA_DIR, \"test.jsonl\"),\n",
        "    }\n",
        ")\n",
        "\n",
        "print(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b729e5a",
        "outputId": "a2eb3d42-3c56-4d7e-cd05-214ef484235d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD9M3Q0K22o5",
        "outputId": "54550531-90cf-4037-c572-37c4b8d7622b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded label map. Num labels: 9\n",
            "Sample id2label: {0: 'B-DATE', 1: 'B-FIN_TERM', 2: 'B-FIN_VALUE', 3: 'B-ORG', 4: 'I-DATE', 5: 'I-FIN_TERM', 6: 'I-FIN_VALUE', 7: 'I-ORG', 8: 'O'}\n"
          ]
        }
      ],
      "source": [
        "# Cell â€” Fix label_map parsing, print ner-tag counts per split, run prediction & seqeval report\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from transformers import TrainingArguments, Trainer, DataCollatorForTokenClassification\n",
        "from seqeval.metrics import classification_report\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "from transformers import AutoTokenizer # Import AutoTokenizer\n",
        "\n",
        "# Assume tokenizer and model are already loaded from previous cells\n",
        "# tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, use_fast=True)\n",
        "# model = AutoModelForTokenClassification.from_pretrained(MODEL_DIR)\n",
        "\n",
        "# ---------- 1) Load/parse label_map.json robustly ----------\n",
        "label_map_path = os.path.join(DATA_DIR, \"label_map.json\")\n",
        "with open(label_map_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    label_map = json.load(f)\n",
        "\n",
        "# common shapes:\n",
        "# a) {\"label2id\": {\"O\":0, \"B-ORG\":1,...}, \"id2label\": {\"0\":\"O\",...}}\n",
        "# b) {\"O\": {\"id\":0}, ...}  (less common)\n",
        "# c) {\"id2label\": {\"0\":\"O\", ...}} or {\"label2id\": {...}}\n",
        "id2label = {}\n",
        "if isinstance(label_map, dict) and \"id2label\" in label_map:\n",
        "    # id2label stored directly (keys probably strings)\n",
        "    id2label = {int(k): v for k, v in label_map[\"id2label\"].items()}\n",
        "elif isinstance(label_map, dict) and \"label2id\" in label_map:\n",
        "    # invert label2id\n",
        "    label2id = label_map[\"label2id\"]\n",
        "    id2label = {int(v): k for k, v in label2id.items()}\n",
        "else:\n",
        "    # fallback: try to find a mapping inside the file\n",
        "    # if file is flat mapping label->id or id->label\n",
        "    # try label->dict with \"id\"\n",
        "    found = False\n",
        "    for k, v in label_map.items():\n",
        "        if isinstance(v, dict) and \"id\" in v:\n",
        "            id2label[int(v[\"id\"])] = k\n",
        "            found = True\n",
        "    if not found:\n",
        "        # try invert if keys are numeric strings\n",
        "        try:\n",
        "            id2label = {int(k): v for k, v in label_map.items()}\n",
        "        except Exception:\n",
        "            raise RuntimeError(\"Unrecognized label_map.json format. Inspect file: \" + label_map_path)\n",
        "\n",
        "\n",
        "# final label list sorted by id\n",
        "label_list = [id2label[i] for i in sorted(id2label.keys())]\n",
        "print(\"Loaded label map. Num labels:\", len(label_list))\n",
        "print(\"Sample id2label:\", dict(list(id2label.items())[:12]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954,
          "referenced_widgets": [
            "7c238bd1d1a046e59a8529ddc141117d",
            "ed18f986f34441bfb9e6ac2addd90eef",
            "420dc63691274093b5bf2e98d783807c",
            "10890123b5984c9d8b6a1452d03dea90",
            "c6fbd97c6952446e8dab81cf72849e4e",
            "862afd7c84304664b5c117adc5663d0d",
            "3e79e9056edf4c789a6ef298e9c04cee",
            "c74095152ad24d39b6dae72b0472b25b",
            "526b9b0512c943c7aa71b4f5ae61b4df",
            "bf2dd154501d4da384024f12adfc351b",
            "3a10a9ca1cc6429ab3859ace06aee283"
          ]
        },
        "id": "7WKnRY-zW3TR",
        "outputId": "0f42145e-c368-4899-aa8e-12c8a2564f40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- train --- rows: 9284 tokens_total: 307911\n",
            "   O               (8): 245914\n",
            "   I-DATE          (4): 25640\n",
            "   B-DATE          (0): 12249\n",
            "   B-ORG           (3): 11404\n",
            "   I-ORG           (7): 9461\n",
            "   I-FIN_VALUE     (6): 1418\n",
            "   B-FIN_VALUE     (2): 1217\n",
            "   I-FIN_TERM      (5): 319\n",
            "   B-FIN_TERM      (1): 289\n",
            "\n",
            "--- validation --- rows: 1161 tokens_total: 27825\n",
            "   O               (8): 21911\n",
            "   I-DATE          (4): 2336\n",
            "   B-ORG           (3): 1140\n",
            "   B-DATE          (0): 1139\n",
            "   I-ORG           (7): 910\n",
            "   I-FIN_VALUE     (6): 159\n",
            "   B-FIN_VALUE     (2): 148\n",
            "   B-FIN_TERM      (1): 43\n",
            "   I-FIN_TERM      (5): 39\n",
            "\n",
            "--- test --- rows: 1161 tokens_total: 23744\n",
            "   O               (8): 17881\n",
            "   I-DATE          (4): 2607\n",
            "   B-DATE          (0): 1205\n",
            "   B-ORG           (3): 880\n",
            "   I-ORG           (7): 750\n",
            "   I-FIN_VALUE     (6): 188\n",
            "   B-FIN_VALUE     (2): 172\n",
            "   B-FIN_TERM      (1): 34\n",
            "   I-FIN_TERM      (5): 27\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c238bd1d1a046e59a8529ddc141117d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1161 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4228043959.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(model=model, args=args, tokenizer=tokenizer, data_collator=data_collator) # Pass the model and tokenizer loaded earlier\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running prediction on test split (this may take a bit)...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted predictions -> BIO labels. Examples: 1161\n",
            "\n",
            "=== SeqEval classification report (test set) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        DATE     0.8512    0.9216    0.8850      1161\n",
            "    FIN_TERM     0.0522    0.3750    0.0916        32\n",
            "   FIN_VALUE     0.6198    0.8721    0.7246       172\n",
            "         ORG     0.4422    0.6739    0.5340       834\n",
            "\n",
            "   micro avg     0.5980    0.8158    0.6901      2199\n",
            "   macro avg     0.4914    0.7106    0.5588      2199\n",
            "weighted avg     0.6664    0.8158    0.7278      2199\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ---------- 2) Print token counts (ner tag counts) per split ----------\n",
        "def count_tag_ids(split):\n",
        "    cnt = Counter()\n",
        "    for arr in split[\"ner_tags\"]:\n",
        "        cnt.update(arr)\n",
        "    return cnt\n",
        "\n",
        "for split_name in (\"train\",\"validation\",\"test\"):\n",
        "    cnt = count_tag_ids(dataset[split_name])\n",
        "    # convert to readable mapping\n",
        "    readable = { (id2label[i] if i in id2label else str(i)): c for i,c in cnt.items() }\n",
        "    total_tokens = sum(cnt.values())\n",
        "    print(f\"\\n--- {split_name} --- rows: {len(dataset[split_name])} tokens_total: {total_tokens}\")\n",
        "    # show top 12 counts (exclude -100 if present)\n",
        "    if -100 in cnt:\n",
        "        print(\"  ignored tokens (-100):\", cnt[-100])\n",
        "    top = Counter({k:v for k,v in cnt.items() if k != -100}).most_common(12)\n",
        "    for tid, c in top:\n",
        "        lbl = id2label.get(tid, str(tid))\n",
        "        print(f\"   {lbl:15s} ({tid}): {c}\")\n",
        "\n",
        "# ---------- Preprocess data for model prediction ----------\n",
        "# Function to tokenize and align labels\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
        "    )\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "# Apply preprocessing to the test dataset\n",
        "tokenized_dataset = dataset[\"test\"].map(tokenize_and_align_labels, batched=True)\n",
        "\n",
        "\n",
        "# ---------- 3) Prepare Trainer for prediction ----------\n",
        "# minimal TrainingArguments for predict\n",
        "args = TrainingArguments(output_dir=\"./tmp_eval\", per_device_eval_batch_size=16, report_to=\"none\")\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "\n",
        "trainer = Trainer(model=model, args=args, tokenizer=tokenizer, data_collator=data_collator) # Pass the model and tokenizer loaded earlier\n",
        "\n",
        "# ---------- 4) Run prediction on test split ----------\n",
        "print(\"\\nRunning prediction on test split (this may take a bit)...\")\n",
        "pred_out = trainer.predict(tokenized_dataset)   # Use the tokenized dataset\n",
        "logits = pred_out.predictions  # shape (num_examples, seq_len, num_labels)\n",
        "label_ids = pred_out.label_ids\n",
        "\n",
        "pred_ids = np.argmax(logits, axis=-1)\n",
        "\n",
        "# ---------- 5) Convert ids -> label strings (ignore -100) ----------\n",
        "def ids_to_label_seqs(pred_array, label_id_array):\n",
        "    pred_seqs = []\n",
        "    true_seqs = []\n",
        "    for p_row, t_row in zip(pred_array, label_id_array):\n",
        "        p_list = []\n",
        "        t_list = []\n",
        "        for p, t in zip(p_row, t_row):\n",
        "            if int(t) == -100:\n",
        "                continue\n",
        "            p_list.append(id2label.get(int(p), \"O\"))\n",
        "            t_list.append(id2label.get(int(t), \"O\"))\n",
        "        pred_seqs.append(p_list)\n",
        "        true_seqs.append(t_list)\n",
        "    return pred_seqs, true_seqs\n",
        "\n",
        "pred_label_seqs, true_label_seqs = ids_to_label_seqs(pred_ids, label_ids)\n",
        "print(\"Converted predictions -> BIO labels. Examples:\", len(pred_label_seqs))\n",
        "\n",
        "# ---------- 6) SeqEval classification report ----------\n",
        "print(\"\\n=== SeqEval classification report (test set) ===\")\n",
        "print(classification_report(true_label_seqs, pred_label_seqs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRK8rpMb1kSB",
        "outputId": "4e171c93-de66-43eb-fe67-c19df0df99b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Text: Apple's revenue in Q3 was $83.4 billion.\n",
            "Predicted Entities:\n",
            "Apple's: B-ORG\n",
            "revenue: O\n",
            "in: O\n",
            "Q3: B-DATE\n",
            "was: O\n",
            "$83.4: O\n",
            "billion.: I-FIN_VALUE\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def predict_ner(text, tokenizer, model, id2label):\n",
        "    # Tokenize the input text\n",
        "    tokens = text.split() # Simple split, can be improved for better tokenization\n",
        "\n",
        "    # Prepare input for the model\n",
        "    tokenized_inputs = tokenizer(\n",
        "        tokens,\n",
        "        is_split_into_words=True,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True\n",
        "    )\n",
        "\n",
        "    # Move input to the same device as the model\n",
        "    device = model.device\n",
        "    input_ids = tokenized_inputs[\"input_ids\"].to(device)\n",
        "    attention_mask = tokenized_inputs[\"attention_mask\"].to(device)\n",
        "\n",
        "    # Get model predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1).squeeze().tolist()\n",
        "\n",
        "    # Align predictions with original tokens\n",
        "    word_ids = tokenized_inputs.word_ids(batch_index=0)\n",
        "    aligned_tags = []\n",
        "    previous_word_idx = None\n",
        "    for word_idx, pred_id in zip(word_ids, predictions):\n",
        "        if word_idx is not None and word_idx != previous_word_idx:\n",
        "            aligned_tags.append(id2label.get(pred_id, \"O\"))\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    return list(zip(tokens, aligned_tags))\n",
        "\n",
        "# Example Usage:\n",
        "text_input = \"Apple's revenue in Q3 was $83.4 billion.\"\n",
        "predicted_entities = predict_ner(text_input, tokenizer, model, id2label)\n",
        "\n",
        "print(\"Input Text:\", text_input)\n",
        "print(\"Predicted Entities:\")\n",
        "for token, tag in predicted_entities:\n",
        "    print(f\"{token}: {tag}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ8pb6rbdtlQ",
        "outputId": "679dd630-a7da-40dc-a566-01abf61532ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "âœ… Model and tokenizer loaded successfully.\n",
            "âœ… Label map loaded. Num labels: 9\n",
            "Sample id2label: {0: 'B-DATE', 1: 'B-FIN_TERM', 2: 'B-FIN_VALUE', 3: 'B-ORG', 4: 'I-DATE', 5: 'I-FIN_TERM', 6: 'I-FIN_VALUE', 7: 'I-ORG', 8: 'O'}\n",
            "âœ… Loaded 1161 test samples.\n"
          ]
        }
      ],
      "source": [
        "# --- Step 1: Load Everything ---\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from collections import defaultdict, Counter\n",
        "import os\n",
        "\n",
        "# Paths - Adjust these if your paths are different\n",
        "# Use the path where the model checkpoint was saved during training\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Finance-Insight/data/finbert_ner_weighted/checkpoint-9284\" #\"ProsusAI/finbert\"#\n",
        "# Use the path to your test data and label map\n",
        "TEST_FILE = \"/content/drive/MyDrive/Finance-Insight/data/processed/ner_auto_splits/test.jsonl\"\n",
        "LABEL_MAP_FILE = \"/content/drive/MyDrive/Finance-Insight/data/processed/ner_auto_splits/label_map.json\"\n",
        "\n",
        "# Load model and tokenizer\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "try:\n",
        "    model = AutoModelForTokenClassification.from_pretrained(MODEL_PATH).to(device)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "    print(\"âœ… Model and tokenizer loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model or tokenizer: {e}\")\n",
        "    print(f\"Please verify the MODEL_PATH: {MODEL_PATH}\")\n",
        "    # Optionally, you could fall back to loading from the base model if needed\n",
        "    # model = AutoModelForTokenClassification.from_pretrained(\"ProsusAI/finbert\").to(device)\n",
        "    # tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
        "    raise # Re-raise the error as we need the fine-tuned model\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Load label map\n",
        "try:\n",
        "    with open(LABEL_MAP_FILE, 'r', encoding='utf-8') as f:\n",
        "        label_map = json.load(f)\n",
        "\n",
        "    id2label = {}\n",
        "    if isinstance(label_map, dict) and \"id2label\" in label_map:\n",
        "        id2label = {int(k): v for k, v in label_map[\"id2label\"].items()}\n",
        "    elif isinstance(label_map, dict) and \"label2id\" in label_map:\n",
        "        label2id = label_map[\"label2id\"]\n",
        "        id2label = {int(v): k for k, v in label2id.items()}\n",
        "    else:\n",
        "         try:\n",
        "             id2label = {int(k): v for k, v in label_map.items()}\n",
        "         except Exception:\n",
        "             raise RuntimeError(\"Unrecognized label_map.json format. Inspect file: \" + LABEL_MAP_FILE)\n",
        "\n",
        "    print(f\"âœ… Label map loaded. Num labels: {len(id2label)}\")\n",
        "    print(\"Sample id2label:\", dict(list(id2label.items())[:12]))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading label map: {e}\")\n",
        "    print(f\"Please verify the LABEL_MAP_FILE: {LABEL_MAP_FILE}\")\n",
        "    raise\n",
        "\n",
        "\n",
        "# Load test data\n",
        "test_samples = []\n",
        "try:\n",
        "    with open(TEST_FILE, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            test_samples.append(json.loads(line))\n",
        "    print(f\"âœ… Loaded {len(test_samples)} test samples.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading test data: {e}\")\n",
        "    print(f\"Please verify the TEST_FILE: {TEST_FILE}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4fe6b75",
        "outputId": "e616120e-c53f-4b06-a2ce-39394652b433"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing sample 0/1161\n",
            "Processing sample 100/1161\n",
            "Processing sample 200/1161\n",
            "Processing sample 300/1161\n",
            "Processing sample 400/1161\n",
            "Processing sample 500/1161\n",
            "Processing sample 600/1161\n",
            "Processing sample 700/1161\n",
            "Processing sample 800/1161\n",
            "Processing sample 900/1161\n",
            "Processing sample 1000/1161\n",
            "Processing sample 1100/1161\n",
            "\n",
            "Finished running inference on the test set.\n",
            "Generated predictions for 1161 samples.\n"
          ]
        }
      ],
      "source": [
        "# --- Step 2: Run Inference on Test Set ---\n",
        "\n",
        "def predict_tags(tokens, tokenizer, model, id2label, device):\n",
        "    \"\"\"Run inference on a list of tokens and return aligned predictions.\"\"\"\n",
        "    tokenized = tokenizer(\n",
        "        tokens,\n",
        "        is_split_into_words=True,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True\n",
        "    )\n",
        "\n",
        "    input_ids = tokenized[\"input_ids\"].to(device)\n",
        "    attention_mask = tokenized[\"attention_mask\"].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1).squeeze().tolist()\n",
        "\n",
        "    # Align predictions to original tokens\n",
        "    word_ids = tokenized.word_ids(batch_index=0)\n",
        "    aligned_predictions = []\n",
        "    previous_word_idx = None\n",
        "\n",
        "    # Handle the case where predictions is a single integer (for very short inputs)\n",
        "    if isinstance(predictions, int):\n",
        "        predictions = [predictions]\n",
        "\n",
        "    for word_idx, pred_id in zip(word_ids, predictions):\n",
        "        if word_idx is not None and word_idx != previous_word_idx:\n",
        "            # Ensure pred_id is a valid key in id2label\n",
        "            aligned_predictions.append(id2label.get(pred_id, \"O\")) # Default to \"O\" if id is not found\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    # Since padding can add extra tokens, we need to ensure the number of predictions\n",
        "    # matches the number of original tokens. We can truncate or align based on word_ids.\n",
        "    # The current logic aligns based on word_ids, so we should return one tag per original token.\n",
        "    # We need to make sure we don't have more aligned_predictions than original tokens.\n",
        "    return aligned_predictions[:len(tokens)]\n",
        "\n",
        "\n",
        "# Run inference on all test samples\n",
        "test_predictions = []\n",
        "for i, sample in enumerate(test_samples):\n",
        "    if i % 100 == 0:\n",
        "        print(f\"Processing sample {i}/{len(test_samples)}\")\n",
        "    tokens = sample[\"tokens\"]\n",
        "    predicted_tags = predict_tags(tokens, tokenizer, model, id2label, device)\n",
        "    test_predictions.append(predicted_tags)\n",
        "\n",
        "print(\"\\nFinished running inference on the test set.\")\n",
        "print(f\"Generated predictions for {len(test_predictions)} samples.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5460da48",
        "outputId": "1c1f3760-bd4a-47ac-e4e2-bbc6d4e0f406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Token-Level Error Analysis ---\n",
            "\n",
            "Token Type: O\n",
            "  Failed Tokens: 4587\n",
            "  Actual Count: 16619\n",
            "  Predicted Count: 15245\n",
            "  Correct Count: 12032\n",
            "  Precision: 0.7892\n",
            "  Recall: 0.7240\n",
            "  F1-score: 0.7552\n",
            "\n",
            "Token Type: I-DATE\n",
            "  Failed Tokens: 1932\n",
            "  Actual Count: 2462\n",
            "  Predicted Count: 2563\n",
            "  Correct Count: 530\n",
            "  Precision: 0.2068\n",
            "  Recall: 0.2153\n",
            "  F1-score: 0.2109\n",
            "\n",
            "Token Type: B-FIN_VALUE\n",
            "  Failed Tokens: 126\n",
            "  Actual Count: 158\n",
            "  Predicted Count: 230\n",
            "  Correct Count: 32\n",
            "  Precision: 0.1391\n",
            "  Recall: 0.2025\n",
            "  F1-score: 0.1649\n",
            "\n",
            "Token Type: B-DATE\n",
            "  Failed Tokens: 945\n",
            "  Actual Count: 1130\n",
            "  Predicted Count: 1222\n",
            "  Correct Count: 185\n",
            "  Precision: 0.1514\n",
            "  Recall: 0.1637\n",
            "  F1-score: 0.1573\n",
            "\n",
            "Token Type: I-ORG\n",
            "  Failed Tokens: 520\n",
            "  Actual Count: 652\n",
            "  Predicted Count: 1048\n",
            "  Correct Count: 132\n",
            "  Precision: 0.1260\n",
            "  Recall: 0.2025\n",
            "  F1-score: 0.1553\n",
            "\n",
            "Token Type: I-FIN_VALUE\n",
            "  Failed Tokens: 142\n",
            "  Actual Count: 174\n",
            "  Predicted Count: 241\n",
            "  Correct Count: 32\n",
            "  Precision: 0.1328\n",
            "  Recall: 0.1839\n",
            "  F1-score: 0.1542\n",
            "\n",
            "Token Type: B-ORG\n",
            "  Failed Tokens: 620\n",
            "  Actual Count: 762\n",
            "  Predicted Count: 1156\n",
            "  Correct Count: 142\n",
            "  Precision: 0.1228\n",
            "  Recall: 0.1864\n",
            "  F1-score: 0.1481\n",
            "\n",
            "Token Type: B-FIN_TERM\n",
            "  Failed Tokens: 30\n",
            "  Actual Count: 31\n",
            "  Predicted Count: 218\n",
            "  Correct Count: 1\n",
            "  Precision: 0.0046\n",
            "  Recall: 0.0323\n",
            "  F1-score: 0.0080\n",
            "\n",
            "Token Type: I-FIN_TERM\n",
            "  Failed Tokens: 24\n",
            "  Actual Count: 24\n",
            "  Predicted Count: 89\n",
            "  Correct Count: 0\n",
            "  Precision: 0.0000\n",
            "  Recall: 0.0000\n",
            "  F1-score: 0.0000\n"
          ]
        }
      ],
      "source": [
        "# --- Step 3: Perform Token-Level Analysis ---\n",
        "\n",
        "# Flatten the lists of true and predicted tags\n",
        "true_tags_flat = [tag for sample in test_samples for tag in sample[\"ner_tags\"]]\n",
        "predicted_tags_flat = [tag_list for pred_sample in test_predictions for tag_list in pred_sample]\n",
        "\n",
        "# Convert numerical tags to labels using id2label\n",
        "true_labels_flat = [id2label.get(tag_id, \"O\") for tag_id in true_tags_flat]\n",
        "# predicted_labels_flat = [id2label.get(tag_id, \"O\") for tag_id in predicted_tags_flat]\n",
        "\n",
        "# We need to align the predicted tags with the true tags,\n",
        "# considering that the inference function returns one tag per original token.\n",
        "# The `test_predictions` list already contains lists of predicted tags aligned to original tokens.\n",
        "# We need to flatten this structure correctly.\n",
        "\n",
        "# Flatten the predicted tags, ensuring alignment with true tags\n",
        "# (This assumes the predict_tags function returns a list of the same length as the input tokens)\n",
        "predicted_labels_flat = []\n",
        "for i, sample in enumerate(test_samples):\n",
        "    # Ensure predicted_tags has the same length as original tokens\n",
        "    predicted_labels_flat.extend(test_predictions[i][:len(sample[\"tokens\"])])\n",
        "\n",
        "# Ensure both lists have the same length for comparison\n",
        "min_len = min(len(true_labels_flat), len(predicted_labels_flat))\n",
        "true_labels_flat = true_labels_flat[:min_len]\n",
        "predicted_labels_flat = predicted_labels_flat[:min_len]\n",
        "\n",
        "\n",
        "# Calculate metrics per token type\n",
        "token_metrics = defaultdict(lambda: {\"correct\": 0, \"predicted\": 0, \"actual\": 0})\n",
        "\n",
        "for true_tag, predicted_tag in zip(true_labels_flat, predicted_labels_flat):\n",
        "    token_metrics[true_tag][\"actual\"] += 1\n",
        "    token_metrics[predicted_tag][\"predicted\"] += 1\n",
        "    if true_tag == predicted_tag:\n",
        "        token_metrics[true_tag][\"correct\"] += 1\n",
        "\n",
        "# Calculate precision, recall, and f1-score for each token type\n",
        "results = {}\n",
        "for tag, counts in token_metrics.items():\n",
        "    correct = counts[\"correct\"]\n",
        "    predicted = counts[\"predicted\"]\n",
        "    actual = counts[\"actual\"]\n",
        "\n",
        "    precision = correct / predicted if predicted > 0 else 0\n",
        "    recall = correct / actual if actual > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    results[tag] = {\n",
        "        \"failed_tokens\": actual - correct, # Number of tokens where the true tag was this tag, but prediction was different\n",
        "        \"actual_count\": actual, # Total count of this true tag\n",
        "        \"predicted_count\": predicted, # Total count of this predicted tag\n",
        "        \"correct_count\": correct, # Count of correct predictions for this tag\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1-score\": f1\n",
        "    }\n",
        "\n",
        "# Print the results\n",
        "print(\"--- Token-Level Error Analysis ---\")\n",
        "# Sort results by F1-score or failed tokens for easier analysis\n",
        "sorted_results = sorted(results.items(), key=lambda item: item[1][\"f1-score\"], reverse=True)\n",
        "\n",
        "for tag, metrics in sorted_results:\n",
        "    print(f\"\\nToken Type: {tag}\")\n",
        "    print(f\"  Failed Tokens: {metrics['failed_tokens']}\")\n",
        "    print(f\"  Actual Count: {metrics['actual_count']}\")\n",
        "    print(f\"  Predicted Count: {metrics['predicted_count']}\")\n",
        "    print(f\"  Correct Count: {metrics['correct_count']}\")\n",
        "    print(f\"  Precision: {metrics['precision']:.4f}\")\n",
        "    print(f\"  Recall: {metrics['recall']:.4f}\")\n",
        "    print(f\"  F1-score: {metrics['f1-score']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lc1Vv1H6ZDmG"
      },
      "outputs": [],
      "source": [
        "# OFFSET-AWARE NER SPAN EXTRACTOR (no overlap with your existing predict_ner)\n",
        "import torch\n",
        "\n",
        "def ner_spans_with_offsets(text: str):\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        enc = tokenizer(\n",
        "            text,\n",
        "            return_tensors=\"pt\",\n",
        "            return_offsets_mapping=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        offsets = enc.pop(\"offset_mapping\")[0].tolist()\n",
        "        enc = {k: v.to(model.device) for k, v in enc.items()}\n",
        "        logits = model(**enc).logits[0]                # [seq_len, num_labels]\n",
        "        probs = logits.softmax(-1)\n",
        "        pred_ids = probs.argmax(-1).tolist()\n",
        "\n",
        "    # prefer model.config.id2label if available\n",
        "    _id2label = getattr(getattr(model, \"config\", object()), \"id2label\", None) or id2label\n",
        "\n",
        "    spans, current = [], None\n",
        "    for i, pid in enumerate(pred_ids):\n",
        "        s, e = offsets[i]\n",
        "        if (s, e) == (0, 0):\n",
        "            continue  # special tokens\n",
        "        lab = _id2label.get(pid, \"O\")\n",
        "        if lab.startswith(\"B-\"):\n",
        "            if current: spans.append(current)\n",
        "            current = {\"label\": lab[2:], \"start\": s, \"end\": e, \"score\": probs[i, pid].item()}\n",
        "        elif lab.startswith(\"I-\") and current and current[\"label\"] == lab[2:]:\n",
        "            current[\"end\"] = e\n",
        "            current[\"score\"] = max(current[\"score\"], probs[i, pid].item())\n",
        "        else:\n",
        "            if current: spans.append(current)\n",
        "            current = None\n",
        "    if current: spans.append(current)\n",
        "\n",
        "    for sp in spans:\n",
        "        sp[\"text\"] = text[sp[\"start\"]:sp[\"end\"]]\n",
        "    return spans\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EcJXzcOsboMq"
      },
      "outputs": [],
      "source": [
        "# New helper imports for Milestone 3\n",
        "import re\n",
        "from typing import List, Dict, Any\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ac8Q3DA4brLv"
      },
      "outputs": [],
      "source": [
        "def normalize_money(text: str):\n",
        "    \"\"\"Normalize money strings like '$12B' â†’ {'value': 12.0, 'unit': 'B', 'currency': 'USD'}.\"\"\"\n",
        "    pattern = r\"\\$?\\s?([\\d\\.]+)\\s?(billion|million|trillion|bn|m|t)?\"\n",
        "    m = re.search(pattern, text, flags=re.IGNORECASE)\n",
        "    if not m:\n",
        "        return {\"raw\": text}\n",
        "    value = float(m.group(1))\n",
        "    unit = (m.group(2) or \"\").lower()\n",
        "    mult = {\"billion\":1e9,\"bn\":1e9,\"million\":1e6,\"m\":1e6,\"trillion\":1e12,\"t\":1e12}.get(unit,1)\n",
        "    return {\"raw\": text, \"value\": value*mult, \"unit\": unit, \"currency\": \"USD\"}\n",
        "\n",
        "def normalize_percent(text: str):\n",
        "    \"\"\"Normalize percent strings like '5%' â†’ 0.05\"\"\"\n",
        "    m = re.search(r\"([\\d\\.]+)%\", text)\n",
        "    return {\"raw\": text, \"value\": float(m.group(1))/100 if m else None}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "r1Kk3xTlcFZc"
      },
      "outputs": [],
      "source": [
        "def user_defined_extraction(text: str, user_entities: List[str]) -> Dict[str, List[Dict[str, Any]]]:\n",
        "    \"\"\"Extract user-specified financial entities using regex rules.\"\"\"\n",
        "    results = {ent: [] for ent in user_entities}\n",
        "\n",
        "    if \"market_cap\" in user_entities:\n",
        "        for match in re.findall(r\"market cap(?:italization)?(?: is| of)? \\$?\\d+(?:\\.\\d+)? ?(?:billion|million|trillion)?\", text, flags=re.I):\n",
        "            results[\"market_cap\"].append(normalize_money(match))\n",
        "\n",
        "    if \"EPS\" in user_entities:\n",
        "        for match in re.findall(r\"EPS(?: is| of)? \\$?\\d+(?:\\.\\d+)?\", text, flags=re.I):\n",
        "            results[\"EPS\"].append(normalize_money(match))\n",
        "\n",
        "    if \"revenue_growth\" in user_entities:\n",
        "    # Handles: \"Revenue growth rose by 8%\", \"Sales grew 8%\", \"Revenue increased 8%\"\n",
        "        for pct in re.findall(r\"(?:revenue|sales)\\s*(?:growth|grew|rose|increased|decreased|fell)\\s*(?:by\\s*)?(\\d{1,3}(?:\\.\\d+)?)\\s*%\", text, flags=re.I):\n",
        "            results[\"revenue_growth\"].append(normalize_percent(pct + \"%\"))\n",
        "\n",
        "    if \"stock_price_trend\" in user_entities:\n",
        "        # Handles: \"stock price rose 5%\", \"shares fell by 3%\", \"stock decreased 2%\"\n",
        "        for m in re.findall(r\"(?:stock price|shares|stock)\\s+(?:rose|fell|increased|decreased|gained|lost|up|down)\\s+(?:by\\s*)?\\d{1,3}(?:\\.\\d+)?\\s*%\", text, flags=re.I):\n",
        "            results[\"stock_price_trend\"].append({\"raw\": m})\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "A9UFzfPrcMHA"
      },
      "outputs": [],
      "source": [
        "def detect_financial_events(text: str, event_types: List[str]) -> Dict[str, List[str]]:\n",
        "    \"\"\"Detect high-level financial events by keywords.\"\"\"\n",
        "    key_map = {\n",
        "        \"M&A\": [\"merger\",\"acquisition\",\"acquire\",\"merged\",\"acquired\",\"buyout\"],\n",
        "        \"IPO\": [\"ipo\",\"initial public offering\",\"went public\"],\n",
        "        \"earnings_call\": [\"earnings call\",\"quarterly results\",\"conference call\"],\n",
        "        \"dividend\": [\"dividend declared\",\"dividend announced\",\"dividend payout\"],\n",
        "    }\n",
        "    events = {et: [] for et in event_types}\n",
        "    for sent in re.split(r'(?<=[.!?]) +', text):\n",
        "        low = sent.lower()\n",
        "        for et in event_types:\n",
        "            if any(k in low for k in key_map.get(et, [])):\n",
        "                events[et].append(sent.strip())\n",
        "    return events\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x46CAd1TcRJY",
        "outputId": "995804c5-21e1-421e-f740-27999c0790e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rule-based entities:\n",
            " {'market_cap': [{'raw': 'market capitalization is $12 billion', 'value': 12000000000.0, 'unit': 'billion', 'currency': 'USD'}], 'EPS': [{'raw': 'EPS is $3.50', 'value': 3.5, 'unit': '', 'currency': 'USD'}], 'revenue_growth': [], 'stock_price_trend': [{'raw': 'stock price rose 5%'}]}\n",
            "\n",
            "Detected events:\n",
            " {'M&A': [], 'IPO': ['The stock price rose 5% after the IPO announcement.'], 'earnings_call': [], 'dividend': []}\n"
          ]
        }
      ],
      "source": [
        "sample_text = \"\"\"\n",
        "The company's market capitalization is $12 billion. EPS is $3.50 this quarter.\n",
        "Revenue growth rose by 8%. The stock price rose 5% after the IPO announcement.\n",
        "\"\"\"\n",
        "\n",
        "user_entities = [\"market_cap\", \"EPS\", \"revenue_growth\", \"stock_price_trend\"]\n",
        "event_types = [\"M&A\", \"IPO\", \"earnings_call\", \"dividend\"]\n",
        "\n",
        "# NER already available from your model â€” we just use rule layer here\n",
        "rule_results = user_defined_extraction(sample_text, user_entities)\n",
        "events = detect_financial_events(sample_text, event_types)\n",
        "\n",
        "print(\"Rule-based entities:\\n\", rule_results)\n",
        "print(\"\\nDetected events:\\n\", events)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "yzFijZhEi1JC"
      },
      "outputs": [],
      "source": [
        "# Runs your fine-tuned NER to get character-accurate spans + confidence.\n",
        "import torch\n",
        "\n",
        "def ner_infer(text: str, conf_threshold: float = 0.50):\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        enc = tokenizer(\n",
        "            text,\n",
        "            return_tensors=\"pt\",\n",
        "            return_offsets_mapping=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        enc = {k: v.to(model.device) for k, v in enc.items()}\n",
        "        offsets = enc[\"offset_mapping\"][0].tolist()\n",
        "        logits = model(**{k: v for k, v in enc.items() if k != \"offset_mapping\"}).logits[0]\n",
        "        probs = logits.softmax(-1)\n",
        "\n",
        "    spans = []\n",
        "    current = None\n",
        "    for i, (s, e) in enumerate(offsets):\n",
        "        if s == e:  # special tokens\n",
        "            continue\n",
        "        pred_id = int(probs[i].argmax().item())\n",
        "        label = id2label.get(pred_id, \"O\")\n",
        "        score = float(probs[i, pred_id].item())\n",
        "\n",
        "        if label.startswith(\"B-\") and score >= conf_threshold:\n",
        "            if current:\n",
        "                spans.append(current)\n",
        "            current = {\"label\": label[2:], \"start\": s, \"end\": e, \"score\": score}\n",
        "        elif label.startswith(\"I-\") and current and current[\"label\"] == label[2:]:\n",
        "            current[\"end\"] = e\n",
        "            current[\"score\"] = max(current[\"score\"], score)\n",
        "        else:\n",
        "            if current:\n",
        "                spans.append(current)\n",
        "            current = None\n",
        "    if current:\n",
        "        spans.append(current)\n",
        "\n",
        "    for sp in spans:\n",
        "        sp[\"text\"] = text[sp[\"start\"]:sp[\"end\"]]\n",
        "    return spans\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "g685kb4VjB-W"
      },
      "outputs": [],
      "source": [
        "# Maps model labels â†’ user-visible entities; edit/extend to your label set.\n",
        "LABEL_TO_ENTITY = {\n",
        "    \"MARKET_CAP\": \"market_cap\",\n",
        "    \"EPS_VALUE\": \"EPS\",\n",
        "    \"REVENUE_GROWTH\": \"revenue_growth\",\n",
        "    \"PRICE_TREND\": \"stock_price_trend\",\n",
        "    # add more: \"NET_INCOME\": \"net_income\", etc.\n",
        "}\n",
        "\n",
        "def map_ner_to_user_entities(ner_spans, user_entities):\n",
        "    out = {e: [] for e in user_entities}\n",
        "    for sp in ner_spans:\n",
        "        ent = LABEL_TO_ENTITY.get(sp[\"label\"])\n",
        "        if ent in user_entities:\n",
        "            out[ent].append({\n",
        "                \"source\": \"ner\",\n",
        "                \"text\": sp[\"text\"],\n",
        "                \"start\": sp[\"start\"],\n",
        "                \"end\": sp[\"end\"],\n",
        "                \"confidence\": sp[\"score\"]\n",
        "            })\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "7oAvUDbojIOs"
      },
      "outputs": [],
      "source": [
        "# Combines NER results with your existing rule-based results; removes duplicates.\n",
        "def merge_extractions(text: str, user_entities, conf_threshold: float = 0.50):\n",
        "    ner_spans = ner_infer(text, conf_threshold=conf_threshold)\n",
        "    ner_dict = map_ner_to_user_entities(ner_spans, user_entities)\n",
        "    rule_dict = user_defined_extraction(text, user_entities)  # <-- already defined earlier\n",
        "\n",
        "    merged = {e: [] for e in user_entities}\n",
        "\n",
        "    # helper: make a simple dedup key on lowercased text (and value if present)\n",
        "    def k(v):\n",
        "        if isinstance(v, dict) and \"text\" in v:\n",
        "            return (\"ner\", v[\"text\"].strip().lower())\n",
        "        if isinstance(v, dict) and \"raw\" in v:\n",
        "            return (\"rule\", v[\"raw\"].strip().lower())\n",
        "        return (\"rule\", str(v).strip().lower())\n",
        "\n",
        "    seen = set()\n",
        "\n",
        "    # add NER first (prefer model spans), then rules\n",
        "    for e in user_entities:\n",
        "        for v in ner_dict.get(e, []):\n",
        "            key = (e, k(v))\n",
        "            if key not in seen:\n",
        "                merged[e].append(v)\n",
        "                seen.add(key)\n",
        "        for v in rule_dict.get(e, []):\n",
        "            key = (e, k(v))\n",
        "            if key not in seen:\n",
        "                # ensure a consistent shape for rule entries\n",
        "                if isinstance(v, dict):\n",
        "                    v = {\"source\": \"rule\", **v}\n",
        "                else:\n",
        "                    v = {\"source\": \"rule\", \"raw\": str(v)}\n",
        "                merged[e].append(v)\n",
        "                seen.add(key)\n",
        "\n",
        "    return merged\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCedCpvnjPXQ",
        "outputId": "311ddb14-f200-472f-88d3-94a36a0b6dc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'market_cap': [{'source': 'rule', 'raw': 'market capitalization is $12 billion', 'value': 12000000000.0, 'unit': 'billion', 'currency': 'USD'}], 'EPS': [{'source': 'rule', 'raw': 'EPS is $3.50', 'value': 3.5, 'unit': '', 'currency': 'USD'}], 'revenue_growth': [], 'stock_price_trend': [{'source': 'rule', 'raw': 'stock price rose 5%'}]}\n"
          ]
        }
      ],
      "source": [
        "# Example usage: change text or pipe real 10-K/10-Q/news content here.\n",
        "text = \"\"\"\n",
        "The company's market capitalization is $12 billion. EPS is $3.50 this quarter.\n",
        "Revenue growth rose by 8%. The stock price rose 5% after the IPO announcement.\n",
        "\"\"\"\n",
        "\n",
        "user_entities = [\"market_cap\", \"EPS\", \"revenue_growth\", \"stock_price_trend\"]\n",
        "hybrid = merge_extractions(text, user_entities, conf_threshold=0.50)\n",
        "print(hybrid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "QEYQDKo5nUvX"
      },
      "outputs": [],
      "source": [
        "# Fixed: robust month lookup supports both full (\"June\") and abbreviated (\"Jun\") names.\n",
        "import re\n",
        "import calendar\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "\n",
        "# Build month map from calendar (handles \"june\" and \"jun\")\n",
        "_MONTHS = {}\n",
        "for i in range(1, 13):\n",
        "    _MONTHS[calendar.month_name[i].lower()] = i\n",
        "    _MONTHS[calendar.month_abbr[i].lower()] = i\n",
        "\n",
        "def _parse_date_from_sentence(sent: str) -> Optional[datetime]:\n",
        "    # very small date parser: \"June 5, 2024\", \"Jun 2024\", \"Q1 2024\", \"2024\"\n",
        "    s = sent.strip()\n",
        "    # Month D, YYYY  | Month YYYY  (day optional)\n",
        "    m = re.search(\n",
        "        r\"(Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|\"\n",
        "        r\"Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\\s+(\\d{1,2})?,?\\s+(\\d{4})\",\n",
        "        s, re.I\n",
        "    )\n",
        "    if m:\n",
        "        key = m.group(1).lower()\n",
        "        month = _MONTHS.get(key) or _MONTHS.get(key[:3])\n",
        "        day = int(m.group(2)) if m.group(2) else 1\n",
        "        year = int(m.group(3))\n",
        "        return datetime(year, month, day)\n",
        "\n",
        "    # Qn YYYY\n",
        "    m = re.search(r\"\\bQ([1-4])\\s+(\\d{4})\\b\", s, re.I)\n",
        "    if m:\n",
        "        q, year = int(m.group(1)), int(m.group(2))\n",
        "        month = (q - 1) * 3 + 1\n",
        "        return datetime(year, month, 1)\n",
        "\n",
        "    # YYYY only\n",
        "    m = re.search(r\"\\b(20\\d{2}|19\\d{2})\\b\", s)\n",
        "    if m:\n",
        "        return datetime(int(m.group(1)), 1, 1)\n",
        "\n",
        "    return None\n",
        "\n",
        "_EVENT_KEYWORDS = {\n",
        "    \"M&A\": [\"merger\",\"acquisition\",\"acquire\",\"merged\",\"acquired\",\"buyout\"],\n",
        "    \"IPO\": [\"ipo\",\"initial public offering\",\"went public\",\"listing\",\"listed on\"],\n",
        "    \"stock_split\": [\"stock split\",\"share split\",\"split shares\"],\n",
        "    \"earnings_call\": [\"earnings call\",\"quarterly results\",\"earnings report\",\"conference call\"],\n",
        "    \"dividend\": [\"dividend declared\",\"dividend announced\",\"dividend payout\",\"dividend yield\"],\n",
        "    \"guidance\": [\"guidance\",\"outlook\",\"revenue forecast\",\"earnings guidance\"],\n",
        "    \"rating_change\": [\"credit rating\",\"downgrade\",\"upgrade\",\"rating agency\"],\n",
        "}\n",
        "\n",
        "def detect_financial_events(\n",
        "    text: str,\n",
        "    event_types: List[str],\n",
        "    timeframe: Optional[Tuple[Optional[datetime], Optional[datetime]]] = None\n",
        ") -> Dict[str, List[Dict[str, Any]]]:\n",
        "    \"\"\"Keyword-based event detection; optionally filters events by sentence date if found.\"\"\"\n",
        "    start, end = timeframe or (None, None)\n",
        "    results = {et: [] for et in event_types}\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
        "\n",
        "    for sent in sentences:\n",
        "        low = sent.lower()\n",
        "        for et in event_types:\n",
        "            if any(k in low for k in _EVENT_KEYWORDS.get(et, [])):\n",
        "                d = _parse_date_from_sentence(sent)\n",
        "                if start and d and d < start:\n",
        "                    continue\n",
        "                if end and d and d > end:\n",
        "                    continue\n",
        "                results[et].append({\"sentence\": sent.strip(), \"date\": d.isoformat() if d else None})\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bC8sqyEgpVaq"
      },
      "outputs": [],
      "source": [
        "def extract_tickers(text: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Extract likely tickers with simple context rules:\n",
        "    - Allow patterns near the words 'ticker' or 'symbol'\n",
        "    - Allow uppercase tickers inside parentheses, e.g., (AAPL)\n",
        "    - Drop common finance terms like IPO, EPS, PE, ROE, etc.\n",
        "    \"\"\"\n",
        "    STOP = {\"IPO\",\"EPS\",\"PE\",\"NAV\",\"ROE\",\"ROI\",\"CAGR\",\"EBITDA\",\"EPS\",\"PV\",\"IRR\",\"DCF\",\"FCF\"}\n",
        "    seen, out = set(), []\n",
        "\n",
        "    # Contextual: near 'ticker'/'symbol' OR inside parentheses\n",
        "    for m in re.finditer(r'(\\()?(?P<t>[A-Z]{1,5}(?:\\.[A-Z])?)(\\))?', text):\n",
        "        t = m.group(\"t\")\n",
        "        if t in STOP:\n",
        "            continue\n",
        "        ctx = text[max(0, m.start()-20): m.end()+20].lower()\n",
        "        in_paren = bool(m.group(1)) or text[m.end()-1:m.end()] == \")\"\n",
        "        near_hint = (\"ticker\" in ctx) or (\"symbol\" in ctx)\n",
        "        if in_paren or near_hint:\n",
        "            if t not in seen:\n",
        "                seen.add(t); out.append(t)\n",
        "\n",
        "    # Explicit \"Ticker: XXX\" or \"Symbol - XXX\"\n",
        "    for m in re.finditer(r'(?:ticker|symbol)\\s*[:\\-]\\s*([A-Z]{1,5}(?:\\.[A-Z])?)', text, re.I):\n",
        "        t = m.group(1).upper()\n",
        "        if t not in STOP and t not in seen:\n",
        "            seen.add(t); out.append(t)\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "7nnhY7i0pm4a"
      },
      "outputs": [],
      "source": [
        "# pip install yfinance\n",
        "import yfinance as yf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "DTr-V6k1pXCh"
      },
      "outputs": [],
      "source": [
        "\n",
        "def verify_with_financial_db(extracted: Dict[str, List[dict]], text: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Verifies/enriches using Yahoo Finance:\n",
        "    - Finds tickers in text.\n",
        "    - For each ticker, fetches last price and longName (if available).\n",
        "    \"\"\"\n",
        "    verified = {\"tickers\": []}\n",
        "    for t in extract_tickers(text):\n",
        "        try:\n",
        "            tk = yf.Ticker(t)\n",
        "            info = tk.info or {}\n",
        "            price = info.get(\"regularMarketPrice\")\n",
        "            name = info.get(\"longName\") or info.get(\"shortName\")\n",
        "            if price is not None:\n",
        "                verified[\"tickers\"].append({\"ticker\": t, \"price\": price, \"name\": name or \"N/A\"})\n",
        "        except Exception:\n",
        "            # ignore invalid tickers / network errors\n",
        "            pass\n",
        "    # You can also cross-check values in `extracted` against fetched fundamentals if needed.\n",
        "    return verified\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ggK4ru3cpvF9"
      },
      "outputs": [],
      "source": [
        "def analyze_text(text: str,\n",
        "                 user_entities: List[str],\n",
        "                 event_types: List[str],\n",
        "                 conf_threshold: float = 0.50,\n",
        "                 timeframe: Optional[Tuple[Optional[datetime], Optional[datetime]]] = None):\n",
        "    \"\"\"\n",
        "    Runs: Hybrid entity extraction â†’ Event detection (optional timeframe) â†’ Yahoo verify.\n",
        "    \"\"\"\n",
        "    entities = merge_extractions(text, user_entities, conf_threshold=conf_threshold)  # uses your existing hybrid\n",
        "    events = detect_financial_events(text, event_types, timeframe=timeframe)\n",
        "    verified = verify_with_financial_db(entities, text)\n",
        "    return {\"entities\": entities, \"events\": events, \"verified\": verified}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAmekoafpzE-",
        "outputId": "f2cf3eba-7e8a-4533-806e-2f657adb2640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'entities': {'market_cap': [{'source': 'rule', 'raw': 'market capitalization is $12 billion', 'value': 12000000000.0, 'unit': 'billion', 'currency': 'USD'}], 'EPS': [{'source': 'rule', 'raw': 'EPS is $3.50', 'value': 3.5, 'unit': '', 'currency': 'USD'}], 'revenue_growth': [], 'stock_price_trend': [{'source': 'rule', 'raw': 'stock price rose 5%'}]}, 'events': {'IPO': [{'sentence': 'announced an IPO on June 5, 2024.', 'date': '2024-06-05T00:00:00'}], 'M&A': [], 'earnings_call': [], 'dividend': []}, 'verified': {'tickers': [{'ticker': 'T', 'price': 24.56, 'name': 'AT&T Inc.'}, {'ticker': 'AAPL', 'price': 270.14, 'name': 'Apple Inc.'}]}}\n"
          ]
        }
      ],
      "source": [
        "demo_text = \"\"\"\n",
        "ApexTech Solutions Ltd. announced an IPO on June 5, 2024.\n",
        "The company's market capitalization is $12 billion. EPS is $3.50 this quarter.\n",
        "Revenue growth rose by 8%. The stock price rose 5%. Ticker mentioned: AAPL.\n",
        "\"\"\"\n",
        "\n",
        "user_entities = [\"market_cap\", \"EPS\", \"revenue_growth\", \"stock_price_trend\"]\n",
        "event_types = [\"IPO\", \"M&A\", \"earnings_call\", \"dividend\"]\n",
        "\n",
        "# Example timeframe: only include events from 2024-01-01 to 2024-12-31\n",
        "start_dt = datetime(2010,1,1); end_dt = datetime(2024,12,31)\n",
        "result = analyze_text(demo_text, user_entities, event_types, conf_threshold=0.5, timeframe=(start_dt, end_dt))\n",
        "print(result)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0aebc4913c224f468cd82ed3e07b0660": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1081fb796af642118aad5fd3c119f833": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10890123b5984c9d8b6a1452d03dea90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf2dd154501d4da384024f12adfc351b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3a10a9ca1cc6429ab3859ace06aee283",
            "value": "â€‡1161/1161â€‡[00:00&lt;00:00,â€‡4796.66â€‡examples/s]"
          }
        },
        "10a2be342df542a9aaa3ba4287e5935e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_348cc4e2c2424a4b97f186b0289798ed",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e372ea4130ad4242bffd008ecb707973",
            "value": "Map:â€‡100%"
          }
        },
        "1478ef20576144738fab973b87efce5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d569466312f54cf1a5bbe4957b3061bd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ea9fb3ffce714b9eb2741123565e7440",
            "value": "Map:â€‡100%"
          }
        },
        "17356bdbb44142b7851462890f8792a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "184bd4f7e3f24a8a88f8bcfb7a17cf71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a5352a6190249f79446b71f9e087813": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ff2ffeb2ab24c2b8dda88abe1ba7e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "236ed33de4784713bd49d79329b6d44c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29678a557ff245c8a154142a6aeeb4a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a3d9f72db274c818bf9f94ee89973ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cc7c19373b844349a97bf23f8dd0603",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b6eccd2b148b466fb7c7d42821ae9065",
            "value": "â€‡1161/0â€‡[00:00&lt;00:00,â€‡20693.91â€‡examples/s]"
          }
        },
        "2b5b0357b8104486ae8ef187ef222f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f88bcf477d954762999cbd2564688d0a",
            "max": 9284,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4889e80855d94e7188e609c79cbe2cfe",
            "value": 9284
          }
        },
        "2e652a70f44c489aad07aafd53d76118": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "319bc161f1fc45b2beea125c616875f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "348cc4e2c2424a4b97f186b0289798ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37daae0c1cf24fd7a94f6d00930ad329": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54b7c8ba551948ff917d2b07eee1d631",
              "IPY_MODEL_ef16c7d876e942a0b9e9361110ae0e06",
              "IPY_MODEL_66510a5436f74fd0a0c1edcfab46d1c3"
            ],
            "layout": "IPY_MODEL_a7763f86ce51498ab02c856c503a0be6"
          }
        },
        "3a10a9ca1cc6429ab3859ace06aee283": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e79e9056edf4c789a6ef298e9c04cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "420dc63691274093b5bf2e98d783807c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c74095152ad24d39b6dae72b0472b25b",
            "max": 1161,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_526b9b0512c943c7aa71b4f5ae61b4df",
            "value": 1161
          }
        },
        "4889e80855d94e7188e609c79cbe2cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4be57b662cfa4bba89016f4a6f6474bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d21d03c99d946568b26115bbf04efe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ee064c177eb4019b060657e380eee84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "526b9b0512c943c7aa71b4f5ae61b4df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54b7c8ba551948ff917d2b07eee1d631": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6caa00636b334b75b1b8d06307fd6fa5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1a5352a6190249f79446b71f9e087813",
            "value": "Generatingâ€‡validationâ€‡split:â€‡"
          }
        },
        "577416a876534922b70c7536badd0122": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb3e7b73c4cf442685858e62ad4e295a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c8bfda41da6d4613938c2953d257053e",
            "value": "â€‡9284/0â€‡[00:01&lt;00:00,â€‡8491.33â€‡examples/s]"
          }
        },
        "5a830a34ff9343e597073f198e27f9c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bfded1be3bb44ab8ac23009717c21e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cc7c19373b844349a97bf23f8dd0603": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66510a5436f74fd0a0c1edcfab46d1c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb7a03ceba7148578695389b19379162",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1ff2ffeb2ab24c2b8dda88abe1ba7e50",
            "value": "â€‡1161/0â€‡[00:00&lt;00:00,â€‡22872.00â€‡examples/s]"
          }
        },
        "66d473713de7414ab436bc8dd5e64e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6caa00636b334b75b1b8d06307fd6fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cae79e7036a4e5ea0e8dde6bfefa8aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ac28b2dabc142b094ee82445cb0d0e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aebc4913c224f468cd82ed3e07b0660",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_29678a557ff245c8a154142a6aeeb4a0",
            "value": "â€‡9284/9284â€‡[00:07&lt;00:00,â€‡1364.47â€‡examples/s]"
          }
        },
        "7c238bd1d1a046e59a8529ddc141117d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed18f986f34441bfb9e6ac2addd90eef",
              "IPY_MODEL_420dc63691274093b5bf2e98d783807c",
              "IPY_MODEL_10890123b5984c9d8b6a1452d03dea90"
            ],
            "layout": "IPY_MODEL_c6fbd97c6952446e8dab81cf72849e4e"
          }
        },
        "8221bfa14ec047ee9a1c26deae236a1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "828820ad98e141e1bb72dc46a5128bb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "862afd7c84304664b5c117adc5663d0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dbf640741584c7e90cfe8e06b15744d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10a2be342df542a9aaa3ba4287e5935e",
              "IPY_MODEL_2b5b0357b8104486ae8ef187ef222f10",
              "IPY_MODEL_7ac28b2dabc142b094ee82445cb0d0e6"
            ],
            "layout": "IPY_MODEL_4ee064c177eb4019b060657e380eee84"
          }
        },
        "940f6cf27dc744418a6e2fdb02f5a5e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99fbc9928f3948a1aaa8c842b1c52364": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6b455ce9a8a43d495ecc17a6c54be3d",
              "IPY_MODEL_bbc4d495899744138dfa95452ba0bf64",
              "IPY_MODEL_2a3d9f72db274c818bf9f94ee89973ab"
            ],
            "layout": "IPY_MODEL_2e652a70f44c489aad07aafd53d76118"
          }
        },
        "9b65916548844a5ea2f6fd78350cb8c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1478ef20576144738fab973b87efce5f",
              "IPY_MODEL_c3388b9830fb4009a0d97aa8773ce972",
              "IPY_MODEL_a56cc28f00074585bcda913686bfbec9"
            ],
            "layout": "IPY_MODEL_c348e8f7479a4f66bad3d9f7deda47d2"
          }
        },
        "9d1add1328094d53a7097bae76b31ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9eb02f2f5e35436989f7caeb75e42017": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b88dfaa5165b450e963060273a11c79b",
              "IPY_MODEL_ed6f5fe0c68c4905bfa9c7774b470a33",
              "IPY_MODEL_e37a68362d3d44439abf8fb8dc7ecedc"
            ],
            "layout": "IPY_MODEL_940f6cf27dc744418a6e2fdb02f5a5e9"
          }
        },
        "a43adf59c6ff4d219fc0977e0c383883": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0d360db81a64672a3b44d598e61ba33",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17356bdbb44142b7851462890f8792a5",
            "value": 1
          }
        },
        "a56cc28f00074585bcda913686bfbec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_184bd4f7e3f24a8a88f8bcfb7a17cf71",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e930c4dc12c446478e22d13a6936604b",
            "value": "â€‡1161/1161â€‡[00:00&lt;00:00,â€‡1923.87â€‡examples/s]"
          }
        },
        "a7763f86ce51498ab02c856c503a0be6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6b455ce9a8a43d495ecc17a6c54be3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a830a34ff9343e597073f198e27f9c2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9d1add1328094d53a7097bae76b31ada",
            "value": "Generatingâ€‡testâ€‡split:â€‡"
          }
        },
        "b6eccd2b148b466fb7c7d42821ae9065": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b74f61e70477417e95567f6272516a4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4be57b662cfa4bba89016f4a6f6474bd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6cae79e7036a4e5ea0e8dde6bfefa8aa",
            "value": "Generatingâ€‡trainâ€‡split:â€‡"
          }
        },
        "b88dfaa5165b450e963060273a11c79b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5f17d90d4bc4d5481d8c45ea2b461a0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fac52d14256c47dcb5f8fee97efd9402",
            "value": "Map:â€‡100%"
          }
        },
        "bbc4d495899744138dfa95452ba0bf64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_828820ad98e141e1bb72dc46a5128bb5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d21d03c99d946568b26115bbf04efe3",
            "value": 1
          }
        },
        "bf2dd154501d4da384024f12adfc351b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3388b9830fb4009a0d97aa8773ce972": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_236ed33de4784713bd49d79329b6d44c",
            "max": 1161,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66d473713de7414ab436bc8dd5e64e6e",
            "value": 1161
          }
        },
        "c348e8f7479a4f66bad3d9f7deda47d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5f17d90d4bc4d5481d8c45ea2b461a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6fbd97c6952446e8dab81cf72849e4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c74095152ad24d39b6dae72b0472b25b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8bfda41da6d4613938c2953d257053e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d569466312f54cf1a5bbe4957b3061bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6fa4bcc93a84ab48cd3ad347aa7e8f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0d360db81a64672a3b44d598e61ba33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e372ea4130ad4242bffd008ecb707973": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e37a68362d3d44439abf8fb8dc7ecedc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_319bc161f1fc45b2beea125c616875f6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5bfded1be3bb44ab8ac23009717c21e6",
            "value": "â€‡1161/1161â€‡[00:00&lt;00:00,â€‡1966.93â€‡examples/s]"
          }
        },
        "e6cc996c83bb40c98e95719d949abb76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b74f61e70477417e95567f6272516a4a",
              "IPY_MODEL_a43adf59c6ff4d219fc0977e0c383883",
              "IPY_MODEL_577416a876534922b70c7536badd0122"
            ],
            "layout": "IPY_MODEL_fe0e0cc1a91d4b4893c40500b4c72713"
          }
        },
        "e930c4dc12c446478e22d13a6936604b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea9fb3ffce714b9eb2741123565e7440": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed18f986f34441bfb9e6ac2addd90eef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_862afd7c84304664b5c117adc5663d0d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3e79e9056edf4c789a6ef298e9c04cee",
            "value": "Map:â€‡100%"
          }
        },
        "ed6f5fe0c68c4905bfa9c7774b470a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8221bfa14ec047ee9a1c26deae236a1c",
            "max": 1161,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1081fb796af642118aad5fd3c119f833",
            "value": 1161
          }
        },
        "ef16c7d876e942a0b9e9361110ae0e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f27d2ef2186e425c8b5d6234c62286c1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6fa4bcc93a84ab48cd3ad347aa7e8f9",
            "value": 1
          }
        },
        "f27d2ef2186e425c8b5d6234c62286c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f88bcf477d954762999cbd2564688d0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fac52d14256c47dcb5f8fee97efd9402": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb3e7b73c4cf442685858e62ad4e295a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb7a03ceba7148578695389b19379162": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe0e0cc1a91d4b4893c40500b4c72713": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
